{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbbedb0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Row\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[1;32m      4\u001b[0m spark \u001b[38;5;241m=\u001b[39m SparkSession\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39mappName(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSparkByExamples.com\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mgetOrCreate()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "     \n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
    "    \n",
    "import datetime\n",
    "\n",
    "courses = [\n",
    "    {\n",
    "        'course_id': 1,\n",
    "        'course_title': 'Mastering Python',\n",
    "        'course_published_dt': datetime.date(2021, 1, 14),\n",
    "        'is_active': True,\n",
    "        'last_updated_ts': datetime.datetime(2021, 2, 18, 16, 57, 25)\n",
    "    },\n",
    "    {\n",
    "        'course_id': 2,\n",
    "        'course_title': 'Data Engineering Essentials',\n",
    "        'course_published_dt': datetime.date(2021, 2, 10),\n",
    "        'is_active': True,\n",
    "        'last_updated_ts': datetime.datetime(2021, 3, 5, 12, 7, 33)\n",
    "    },\n",
    "    {\n",
    "        'course_id': 3,\n",
    "        'course_title': 'Mastering Pyspark',\n",
    "        'course_published_dt': datetime.date(2021, 1, 7),\n",
    "        'is_active': True,\n",
    "        'last_updated_ts': datetime.datetime(2021, 4, 6, 10, 5, 42)\n",
    "    },\n",
    "    {\n",
    "        'course_id': 4,\n",
    "        'course_title': 'AWS Essentials',\n",
    "        'course_published_dt': datetime.date(2021, 3, 19),\n",
    "        'is_active': False,\n",
    "        'last_updated_ts': datetime.datetime(2021, 4, 10, 2, 25, 36)\n",
    "    },\n",
    "    {\n",
    "        'course_id': 5,\n",
    "        'course_title': 'Docker 101',\n",
    "        'course_published_dt': datetime.date(2021, 2, 28),\n",
    "        'is_active': True,\n",
    "        'last_updated_ts': datetime.datetime(2021, 3, 21, 7, 18, 52)\n",
    "    }\n",
    "]\n",
    "\n",
    "courses_df = spark.createDataFrame([Row(**course) for course in courses])\n",
    "     \n",
    "\n",
    "users = [{\n",
    "  \"user_id\": 1,\n",
    "  \"user_first_name\": \"Sandra\",\n",
    "  \"user_last_name\": \"Karpov\",\n",
    "  \"user_email\": \"skarpov0@ovh.net\"\n",
    "}, {\n",
    "  \"user_id\": 2,\n",
    "  \"user_first_name\": \"Kari\",\n",
    "  \"user_last_name\": \"Dearth\",\n",
    "  \"user_email\": \"kdearth1@so-net.ne.jp\"\n",
    "}, {\n",
    "  \"user_id\": 3,\n",
    "  \"user_first_name\": \"Joanna\",\n",
    "  \"user_last_name\": \"Spennock\",\n",
    "  \"user_email\": \"jspennock2@redcross.org\"\n",
    "}, {\n",
    "  \"user_id\": 4,\n",
    "  \"user_first_name\": \"Hirsch\",\n",
    "  \"user_last_name\": \"Conaboy\",\n",
    "  \"user_email\": \"hconaboy3@barnesandnoble.com\"\n",
    "}, {\n",
    "  \"user_id\": 5,\n",
    "  \"user_first_name\": \"Loreen\",\n",
    "  \"user_last_name\": \"Malin\",\n",
    "  \"user_email\": \"lmalin4@independent.co.uk\"\n",
    "}, {\n",
    "  \"user_id\": 6,\n",
    "  \"user_first_name\": \"Augy\",\n",
    "  \"user_last_name\": \"Christon\",\n",
    "  \"user_email\": \"achriston5@mlb.com\"\n",
    "}, {\n",
    "  \"user_id\": 7,\n",
    "  \"user_first_name\": \"Trudey\",\n",
    "  \"user_last_name\": \"Choupin\",\n",
    "  \"user_email\": \"tchoupin6@de.vu\"\n",
    "}, {\n",
    "  \"user_id\": 8,\n",
    "  \"user_first_name\": \"Nadine\",\n",
    "  \"user_last_name\": \"Grimsdell\",\n",
    "  \"user_email\": \"ngrimsdell7@sohu.com\"\n",
    "}, {\n",
    "  \"user_id\": 9,\n",
    "  \"user_first_name\": \"Vassily\",\n",
    "  \"user_last_name\": \"Tamas\",\n",
    "  \"user_email\": \"vtamas8@businessweek.com\"\n",
    "}, {\n",
    "  \"user_id\": 10,\n",
    "  \"user_first_name\": \"Wells\",\n",
    "  \"user_last_name\": \"Simpkins\",\n",
    "  \"user_email\": \"wsimpkins9@amazon.co.uk\"\n",
    "}]\n",
    "\n",
    "users_df = spark.createDataFrame([Row(**user) for user in users])\n",
    "     \n",
    "\n",
    "course_enrolments = [{\n",
    "  \"course_enrolment_id\": 1,\n",
    "  \"user_id\": 10,\n",
    "  \"course_id\": 2,\n",
    "  \"price_paid\": 9.99\n",
    "}, {\n",
    "  \"course_enrolment_id\": 2,\n",
    "  \"user_id\": 5,\n",
    "  \"course_id\": 2,\n",
    "  \"price_paid\": 9.99\n",
    "}, {\n",
    "  \"course_enrolment_id\": 3,\n",
    "  \"user_id\": 7,\n",
    "  \"course_id\": 5,\n",
    "  \"price_paid\": 10.99\n",
    "}, {\n",
    "  \"course_enrolment_id\": 4,\n",
    "  \"user_id\": 9,\n",
    "  \"course_id\": 2,\n",
    "  \"price_paid\": 9.99\n",
    "}, {\n",
    "  \"course_enrolment_id\": 5,\n",
    "  \"user_id\": 8,\n",
    "  \"course_id\": 2,\n",
    "  \"price_paid\": 9.99\n",
    "}, {\n",
    "  \"course_enrolment_id\": 6,\n",
    "  \"user_id\": 5,\n",
    "  \"course_id\": 5,\n",
    "  \"price_paid\": 10.99\n",
    "}, {\n",
    "  \"course_enrolment_id\": 7,\n",
    "  \"user_id\": 4,\n",
    "  \"course_id\": 5,\n",
    "  \"price_paid\": 10.99\n",
    "}, {\n",
    "  \"course_enrolment_id\": 8,\n",
    "  \"user_id\": 7,\n",
    "  \"course_id\": 3,\n",
    "  \"price_paid\": 10.99\n",
    "}, {\n",
    "  \"course_enrolment_id\": 9,\n",
    "  \"user_id\": 8,\n",
    "  \"course_id\": 5,\n",
    "  \"price_paid\": 10.99\n",
    "}, {\n",
    "  \"course_enrolment_id\": 10,\n",
    "  \"user_id\": 3,\n",
    "  \"course_id\": 3,\n",
    "  \"price_paid\": 10.99\n",
    "}, {\n",
    "  \"course_enrolment_id\": 11,\n",
    "  \"user_id\": 7,\n",
    "  \"course_id\": 5,\n",
    "  \"price_paid\": 10.99\n",
    "}, {\n",
    "  \"course_enrolment_id\": 12,\n",
    "  \"user_id\": 3,\n",
    "  \"course_id\": 2,\n",
    "  \"price_paid\": 9.99\n",
    "}, {\n",
    "  \"course_enrolment_id\": 13,\n",
    "  \"user_id\": 5,\n",
    "  \"course_id\": 2,\n",
    "  \"price_paid\": 9.99\n",
    "}, {\n",
    "  \"course_enrolment_id\": 14,\n",
    "  \"user_id\": 4,\n",
    "  \"course_id\": 3,\n",
    "  \"price_paid\": 10.99\n",
    "}, {\n",
    "  \"course_enrolment_id\": 15,\n",
    "  \"user_id\": 8,\n",
    "  \"course_id\": 2,\n",
    "  \"price_paid\": 9.99\n",
    "}]\n",
    "\n",
    "course_enrolments_df = spark.createDataFrame([Row(**ce) for ce in course_enrolments])\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7452a26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+--------------+--------------------+\n",
      "|user_id|user_first_name|user_last_name|          user_email|\n",
      "+-------+---------------+--------------+--------------------+\n",
      "|      1|         Sandra|        Karpov|    skarpov0@ovh.net|\n",
      "|      2|           Kari|        Dearth|kdearth1@so-net.n...|\n",
      "|      3|         Joanna|      Spennock|jspennock2@redcro...|\n",
      "+-------+---------------+--------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+---------+--------------------+-------------------+---------+-------------------+\n",
      "|course_id|        course_title|course_published_dt|is_active|    last_updated_ts|\n",
      "+---------+--------------------+-------------------+---------+-------------------+\n",
      "|        1|    Mastering Python|         2021-01-14|     true|2021-02-18 16:57:25|\n",
      "|        2|Data Engineering ...|         2021-02-10|     true|2021-03-05 12:07:33|\n",
      "|        3|   Mastering Pyspark|         2021-01-07|     true|2021-04-06 10:05:42|\n",
      "+---------+--------------------+-------------------+---------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+-------------------+-------+---------+----------+\n",
      "|course_enrolment_id|user_id|course_id|price_paid|\n",
      "+-------------------+-------+---------+----------+\n",
      "|                  1|     10|        2|      9.99|\n",
      "|                  2|      5|        2|      9.99|\n",
      "|                  3|      7|        5|     10.99|\n",
      "+-------------------+-------+---------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_df.show(3)\n",
    "\n",
    "courses_df.show(3)\n",
    "\n",
    "course_enrolments_df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693d91fa",
   "metadata": {},
   "source": [
    "# Overview of Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95dadac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Type of Joins\n",
    "\n",
    "        # Inner Join - join or inner join\n",
    "        # Left or Right Outer Join\n",
    "        # Full Outer Join - a left outer join b union a right outer join b\n",
    "        # Cross Join\n",
    "        \n",
    "# Spark Data Frames have a function called join. It can be used to perform inner or outer or full outer join.\n",
    "# We need to specify join condition for Inner or Outer or Full Outer Join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c8b5480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method join in module pyspark.sql.dataframe:\n",
      "\n",
      "join(other, on=None, how=None) method of pyspark.sql.dataframe.DataFrame instance\n",
      "    Joins with another :class:`DataFrame`, using the given join expression.\n",
      "    \n",
      "    .. versionadded:: 1.3.0\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    other : :class:`DataFrame`\n",
      "        Right side of the join\n",
      "    on : str, list or :class:`Column`, optional\n",
      "        a string for the join column name, a list of column names,\n",
      "        a join expression (Column), or a list of Columns.\n",
      "        If `on` is a string or a list of strings indicating the name of the join column(s),\n",
      "        the column(s) must exist on both sides, and this performs an equi-join.\n",
      "    how : str, optional\n",
      "        default ``inner``. Must be one of: ``inner``, ``cross``, ``outer``,\n",
      "        ``full``, ``fullouter``, ``full_outer``, ``left``, ``leftouter``, ``left_outer``,\n",
      "        ``right``, ``rightouter``, ``right_outer``, ``semi``, ``leftsemi``, ``left_semi``,\n",
      "        ``anti``, ``leftanti`` and ``left_anti``.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    The following performs a full outer join between ``df1`` and ``df2``.\n",
      "    \n",
      "    >>> from pyspark.sql.functions import desc\n",
      "    >>> df.join(df2, df.name == df2.name, 'outer').select(df.name, df2.height)                 .sort(desc(\"name\")).collect()\n",
      "    [Row(name='Bob', height=85), Row(name='Alice', height=None), Row(name=None, height=80)]\n",
      "    \n",
      "    >>> df.join(df2, 'name', 'outer').select('name', 'height').sort(desc(\"name\")).collect()\n",
      "    [Row(name='Tom', height=80), Row(name='Bob', height=85), Row(name='Alice', height=None)]\n",
      "    \n",
      "    >>> cond = [df.name == df3.name, df.age == df3.age]\n",
      "    >>> df.join(df3, cond, 'outer').select(df.name, df3.age).collect()\n",
      "    [Row(name='Alice', age=2), Row(name='Bob', age=5)]\n",
      "    \n",
      "    >>> df.join(df2, 'name').select(df.name, df2.height).collect()\n",
      "    [Row(name='Bob', height=85)]\n",
      "    \n",
      "    >>> df.join(df4, ['name', 'age']).select(df.name, df.age).collect()\n",
      "    [Row(name='Bob', age=5)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(users_df.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5edaf6c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3813192222.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/7z/zf4v6y0d1q5bnv1v6p7tmvq80000gn/T/ipykernel_34196/3813192222.py\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    >>> df.join(df2, 'name', 'outer').select('name', 'height').sort(desc(\"name\")).collect()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# The below on condition is df.name == df2.name, how is \"outer\"\n",
    "\n",
    "df.join(df2, df.name == df2.name, 'outer').select(df.name, df2.height)                 \n",
    "\n",
    "# The below on condition is \"name\" . This way can be applied only when \"name\" column is in both tables\n",
    "    \n",
    ">>> df.join(df2, 'name', 'outer').select('name', 'height').sort(desc(\"name\")).collect()\n",
    "  \n",
    "# we can also have multple conditions in a single condiition\n",
    "    \n",
    ">>> cond = [df.name == df3.name, df.age == df3.age]\n",
    ">>> df.join(df3, cond, 'outer').select(df.name, df3.age).collect()\n",
    "\n",
    "# we ccan also pass a list of common columns as a join condition\n",
    "\n",
    ">>> df.join(df4, ['name', 'age']).select(df.name, df.age).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1638c8",
   "metadata": {},
   "source": [
    "## Define aliases for Spark DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d957672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method alias in module pyspark.sql.dataframe:\n",
      "\n",
      "alias(alias) method of pyspark.sql.dataframe.DataFrame instance\n",
      "    Returns a new :class:`DataFrame` with an alias set.\n",
      "    \n",
      "    .. versionadded:: 1.3.0\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    alias : str\n",
      "        an alias name to be set for the :class:`DataFrame`.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from pyspark.sql.functions import *\n",
      "    >>> df_as1 = df.alias(\"df_as1\")\n",
      "    >>> df_as2 = df.alias(\"df_as2\")\n",
      "    >>> joined_df = df_as1.join(df_as2, col(\"df_as1.name\") == col(\"df_as2.name\"), 'inner')\n",
      "    >>> joined_df.select(\"df_as1.name\", \"df_as2.name\", \"df_as2.age\")                 .sort(desc(\"df_as1.name\")).collect()\n",
      "    [Row(name='Bob', name='Bob', age=5), Row(name='Alice', name='Alice', age=2)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(courses_df.alias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a4a45d9",
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> from pyspark.sql.functions import *\n",
    ">>> df_as1 = df.alias(\"df_as1\") # - returns a dataframe \n",
    "\n",
    "# the alias create a new dataframe with name \"df_as1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "749a35eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|course_id|\n",
      "+---------+\n",
      "|        1|\n",
      "|        2|\n",
      "|        3|\n",
      "|        4|\n",
      "|        5|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "courses_df.alias(\"c\").select(courses_df[\"course_id\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fc32d2",
   "metadata": {},
   "source": [
    "## Inner Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c43d9911",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the user details who have enrolled for the courses.\n",
    "\n",
    "# steps:\n",
    "\n",
    "    # Need to join users_df and course_enrolments_df.\n",
    "    # Here are the fields that needs to be displayed.\n",
    "        # All fields from users_df\n",
    "        # course_id and course_enrolment_id from course_enrolments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c856b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+--------------+--------------------+\n",
      "|user_id|user_first_name|user_last_name|          user_email|\n",
      "+-------+---------------+--------------+--------------------+\n",
      "|      1|         Sandra|        Karpov|    skarpov0@ovh.net|\n",
      "|      2|           Kari|        Dearth|kdearth1@so-net.n...|\n",
      "|      3|         Joanna|      Spennock|jspennock2@redcro...|\n",
      "+-------+---------------+--------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+-------------------+-------+---------+----------+\n",
      "|course_enrolment_id|user_id|course_id|price_paid|\n",
      "+-------------------+-------+---------+----------+\n",
      "|                  1|     10|        2|      9.99|\n",
      "|                  2|      5|        2|      9.99|\n",
      "|                  3|      7|        5|     10.99|\n",
      "+-------------------+-------+---------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_df.show(3)\n",
    "course_enrolments_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca8e8fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+--------------+--------------------+-------------------+---------+----------+\n",
      "|user_id|user_first_name|user_last_name|          user_email|course_enrolment_id|course_id|price_paid|\n",
      "+-------+---------------+--------------+--------------------+-------------------+---------+----------+\n",
      "|      3|         Joanna|      Spennock|jspennock2@redcro...|                 10|        3|     10.99|\n",
      "|      3|         Joanna|      Spennock|jspennock2@redcro...|                 12|        2|      9.99|\n",
      "|      4|         Hirsch|       Conaboy|hconaboy3@barnesa...|                  7|        5|     10.99|\n",
      "+-------+---------------+--------------+--------------------+-------------------+---------+----------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+-------+---------------+--------------+--------------------+-------------------+-------+---------+----------+\n",
      "|user_id|user_first_name|user_last_name|          user_email|course_enrolment_id|user_id|course_id|price_paid|\n",
      "+-------+---------------+--------------+--------------------+-------------------+-------+---------+----------+\n",
      "|      3|         Joanna|      Spennock|jspennock2@redcro...|                 10|      3|        3|     10.99|\n",
      "|      3|         Joanna|      Spennock|jspennock2@redcro...|                 12|      3|        2|      9.99|\n",
      "|      4|         Hirsch|       Conaboy|hconaboy3@barnesa...|                  7|      4|        5|     10.99|\n",
      "+-------+---------------+--------------+--------------------+-------------------+-------+---------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_df.join(course_enrolments_df,\"user_id\",\"inner\").show(3)\n",
    "\n",
    "# in above, we get single user_id column as we assume it is common column with same meaning in both tables\n",
    "\n",
    "# or\n",
    "\n",
    "# \n",
    "users_df. \\\n",
    "    join(course_enrolments_df, users_df.user_id == course_enrolments_df.user_id,\"inner\"). \\\n",
    "    show(3)\n",
    "\n",
    "# In above , we get two user_id columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5265e0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-------------------+\n",
      "|user_id|course_id|course_enrolment_id|\n",
      "+-------+---------+-------------------+\n",
      "|      3|        3|                 10|\n",
      "|      3|        2|                 12|\n",
      "|      4|        5|                  7|\n",
      "+-------+---------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+-------+---------------+--------------+--------------------+---------+-------------------+\n",
      "|user_id|user_first_name|user_last_name|          user_email|course_id|course_enrolment_id|\n",
      "+-------+---------------+--------------+--------------------+---------+-------------------+\n",
      "|      3|         Joanna|      Spennock|jspennock2@redcro...|        3|                 10|\n",
      "|      3|         Joanna|      Spennock|jspennock2@redcro...|        2|                 12|\n",
      "|      4|         Hirsch|       Conaboy|hconaboy3@barnesa...|        5|                  7|\n",
      "+-------+---------------+--------------+--------------------+---------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get all columns from users_df and course_id as well as course_enrolment_id from course_enrolments\n",
    "\n",
    "users_df. \\\n",
    "    join(course_enrolments_df, users_df.user_id == course_enrolments_df.user_id). \\\n",
    "    select(users_df[\"user_id\"], course_enrolments_df['course_id'], course_enrolments_df['course_enrolment_id']). \\\n",
    "    show(3)\n",
    "\n",
    "# Get all columns from users_df and course_id as well as course_enrolment_id from course_enrolments\n",
    "users_df.alias(\"u\"). \\\n",
    "    join(course_enrolments_df, users_df.user_id == course_enrolments_df.user_id). \\\n",
    "    select('u.*', course_enrolments_df['course_id'], course_enrolments_df['course_enrolment_id']). \\\n",
    "    show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17042b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get number of courses enroled by each user\n",
    "# Fails as user_id is part of both the data frames\n",
    "\n",
    "users_df.alias('u'). \\\n",
    "    join(course_enrolments_df.alias('ce'), users_df.user_id == course_enrolments_df.user_id). \\\n",
    "    groupBy('user_id'). \\\n",
    "    count(). \\\n",
    "    show()\n",
    "\n",
    "# This returns error as Join dataframe has two user_id columns  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5753d1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|user_id|count|\n",
      "+-------+-----+\n",
      "|      3|    2|\n",
      "|      4|    2|\n",
      "|      5|    3|\n",
      "+-------+-----+\n",
      "only showing top 3 rows\n",
      "\n",
      "+-------+-----+\n",
      "|user_id|count|\n",
      "+-------+-----+\n",
      "|      3|    2|\n",
      "|      4|    2|\n",
      "|      5|    3|\n",
      "+-------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Succeeds as we are picking up user_id from users_df\n",
    "users_df. \\\n",
    "    join(course_enrolments_df, users_df.user_id == course_enrolments_df.user_id). \\\n",
    "    groupBy(users_df['user_id']). \\\n",
    "    count(). \\\n",
    "    show(3)\n",
    "\n",
    "# or \n",
    "\n",
    "\n",
    "users_df. \\\n",
    "    join(course_enrolments_df, 'user_id'). \\\n",
    "    groupBy('user_id'). \\\n",
    "    count(). \\\n",
    "    show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2cc028",
   "metadata": {},
   "source": [
    "## Outer Join using left "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e68708f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the user details along with course enrolment details (if the user have any course enrolments).\n",
    "\n",
    "# If the users does not have any course enrolments, we need to get all user details. Course details will be substituted with null values.\n",
    "    # Need to perform left or right outer join between users_df and course_enrolments_df.\n",
    "    # We will use left for this lecture. As users_df is from parent table and as we are going to use left outer join, we need to invoke join on top of users_df.\n",
    "    # Here are the fields that needs to be displayed.\n",
    "        # All fields from users_df\n",
    "        # course_id and course_enrolment_id from course_enrolments_df\n",
    "        \n",
    "# For this example using these data frames, using just outer also give same results. But it is not correct to use outer.\n",
    "# how='outer' means full outer join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a6708275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+--------------+--------------------+-------------------+---------+\n",
      "|user_id|user_first_name|user_last_name|          user_email|course_enrolment_id|course_id|\n",
      "+-------+---------------+--------------+--------------------+-------------------+---------+\n",
      "|      1|         Sandra|        Karpov|    skarpov0@ovh.net|               null|     null|\n",
      "|      2|           Kari|        Dearth|kdearth1@so-net.n...|               null|     null|\n",
      "|      3|         Joanna|      Spennock|jspennock2@redcro...|                 10|        3|\n",
      "|      3|         Joanna|      Spennock|jspennock2@redcro...|                 12|        2|\n",
      "+-------+---------------+--------------+--------------------+-------------------+---------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_df. \\\n",
    "    join(course_enrolments_df, users_df.user_id == course_enrolments_df.user_id, 'left').\\\n",
    "     select(users_df[\"*\"],course_enrolments_df.course_enrolment_id, course_enrolments_df.course_id).   \\\n",
    "    show(4)\n",
    "\n",
    "# For this example using these data frames, using just outer also give same results.\n",
    "#       But it is not correct to use outer.\n",
    "\n",
    "# how='outer' means full outer join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1bab3011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+--------------+--------------------+-------------------+-------+---------+----------+\n",
      "|user_id|user_first_name|user_last_name|          user_email|course_enrolment_id|user_id|course_id|price_paid|\n",
      "+-------+---------------+--------------+--------------------+-------------------+-------+---------+----------+\n",
      "|      1|         Sandra|        Karpov|    skarpov0@ovh.net|               null|   null|     null|      null|\n",
      "|      2|           Kari|        Dearth|kdearth1@so-net.n...|               null|   null|     null|      null|\n",
      "|      3|         Joanna|      Spennock|jspennock2@redcro...|                 10|      3|        3|     10.99|\n",
      "+-------+---------------+--------------+--------------------+-------------------+-------+---------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# left or left_outer or leftouter are same.\n",
    "\n",
    "users_df. \\\n",
    "    join(course_enrolments_df, users_df.user_id == course_enrolments_df.user_id, 'left_outer'). \\\n",
    "    show(3)\n",
    "   \n",
    "# we get user_id two times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f237b0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+--------------+--------------------+---------+-------------------+\n",
      "|user_id|user_first_name|user_last_name|          user_email|course_id|course_enrolment_id|\n",
      "+-------+---------------+--------------+--------------------+---------+-------------------+\n",
      "|      1|         Sandra|        Karpov|    skarpov0@ovh.net|     null|               null|\n",
      "|      2|           Kari|        Dearth|kdearth1@so-net.n...|     null|               null|\n",
      "|      3|         Joanna|      Spennock|jspennock2@redcro...|        3|                 10|\n",
      "|      3|         Joanna|      Spennock|jspennock2@redcro...|        2|                 12|\n",
      "|      4|         Hirsch|       Conaboy|hconaboy3@barnesa...|        5|                  7|\n",
      "|      4|         Hirsch|       Conaboy|hconaboy3@barnesa...|        3|                 14|\n",
      "|      5|         Loreen|         Malin|lmalin4@independe...|        2|                  2|\n",
      "|      5|         Loreen|         Malin|lmalin4@independe...|        5|                  6|\n",
      "|      5|         Loreen|         Malin|lmalin4@independe...|        2|                 13|\n",
      "|      6|           Augy|      Christon|  achriston5@mlb.com|     null|               null|\n",
      "|      7|         Trudey|       Choupin|     tchoupin6@de.vu|        5|                  3|\n",
      "|      7|         Trudey|       Choupin|     tchoupin6@de.vu|        3|                  8|\n",
      "|      7|         Trudey|       Choupin|     tchoupin6@de.vu|        5|                 11|\n",
      "|      8|         Nadine|     Grimsdell|ngrimsdell7@sohu.com|        2|                  5|\n",
      "|      8|         Nadine|     Grimsdell|ngrimsdell7@sohu.com|        5|                  9|\n",
      "|      8|         Nadine|     Grimsdell|ngrimsdell7@sohu.com|        2|                 15|\n",
      "|      9|        Vassily|         Tamas|vtamas8@businessw...|        2|                  4|\n",
      "|     10|          Wells|      Simpkins|wsimpkins9@amazon...|        2|                  1|\n",
      "+-------+---------------+--------------+--------------------+---------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_df. \\\n",
    "    join(course_enrolments_df, users_df.user_id == course_enrolments_df.user_id, 'left'). \\\n",
    "    select(users_df['*'], course_enrolments_df['course_id'], course_enrolments_df['course_enrolment_id']). \\\n",
    "    show()\n",
    "\n",
    "# we cant use indexing with alias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e89856",
   "metadata": {},
   "source": [
    "## Get all the users who have not enrolled for any courses\n",
    "* Recommended to use primary key in the child table when comapring with Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2a72a8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+--------------+--------------------+---------+-------------------+\n",
      "|user_id|user_first_name|user_last_name|          user_email|course_id|course_enrolment_id|\n",
      "+-------+---------------+--------------+--------------------+---------+-------------------+\n",
      "|      1|         Sandra|        Karpov|    skarpov0@ovh.net|     null|               null|\n",
      "|      2|           Kari|        Dearth|kdearth1@so-net.n...|     null|               null|\n",
      "|      6|           Augy|      Christon|  achriston5@mlb.com|     null|               null|\n",
      "+-------+---------------+--------------+--------------------+---------+-------------------+\n",
      "\n",
      "+-------+---------------+--------------+--------------------+---------+-------------------+\n",
      "|user_id|user_first_name|user_last_name|          user_email|course_id|course_enrolment_id|\n",
      "+-------+---------------+--------------+--------------------+---------+-------------------+\n",
      "|      1|         Sandra|        Karpov|    skarpov0@ovh.net|     null|               null|\n",
      "|      2|           Kari|        Dearth|kdearth1@so-net.n...|     null|               null|\n",
      "|      6|           Augy|      Christon|  achriston5@mlb.com|     null|               null|\n",
      "+-------+---------------+--------------+--------------------+---------+-------------------+\n",
      "\n",
      "+-------+---------------+--------------+--------------------+---------+-------------------+\n",
      "|user_id|user_first_name|user_last_name|          user_email|course_id|course_enrolment_id|\n",
      "+-------+---------------+--------------+--------------------+---------+-------------------+\n",
      "|      1|         Sandra|        Karpov|    skarpov0@ovh.net|     null|               null|\n",
      "|      2|           Kari|        Dearth|kdearth1@so-net.n...|     null|               null|\n",
      "|      6|           Augy|      Christon|  achriston5@mlb.com|     null|               null|\n",
      "+-------+---------------+--------------+--------------------+---------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Get all the users who have not enrolled for any courses\n",
    "# Recommended to use primary key in the child table when comapring with Null values\n",
    "\n",
    "users_df.join(course_enrolments_df,\"user_id\",\"left\").\\\n",
    "        select(users_df[\"*\"],course_enrolments_df.course_id, course_enrolments_df.course_enrolment_id).\\\n",
    "        filter(\"course_id IS null\").show()\n",
    "\n",
    "# or\n",
    "\n",
    "# users_df.join(course_enrolments_df,\"user_id\",\"left\").\\\n",
    "#         select(users_df[\"*\"],course_enrolments_df.course_id, course_enrolments_df.course_enrolment_id).\\\n",
    "#         where(\"course_id IS null\").show()\n",
    "\n",
    "\n",
    "# # or SQL type syntax\n",
    "\n",
    "# users_df.join(course_enrolments_df,\"user_id\",\"left\").\\\n",
    "#         select(users_df[\"*\"],course_enrolments_df.course_id, course_enrolments_df.course_enrolment_id).\\\n",
    "#         filter(col(\"course_id\").isNull()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631a23d0",
   "metadata": {},
   "source": [
    "# Get number of courses enroled by each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "14e741eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|user_id|count|\n",
      "+-------+-----+\n",
      "|      1|    1|\n",
      "|      2|    1|\n",
      "|      3|    2|\n",
      "|      4|    2|\n",
      "|      5|    3|\n",
      "|      6|    1|\n",
      "|      7|    3|\n",
      "|      8|    3|\n",
      "|      9|    1|\n",
      "|     10|    1|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_df.join(course_enrolments_df,\"user_id\",\"left\").\\\n",
    "        groupBy(\"user_id\").\\\n",
    "        count().show()\n",
    "\n",
    "# here count - Returns the number of rows in this :class:`DataFrame`. so Null is also considered.\n",
    "\n",
    "# filter(col(\"course_id\").isNotNull()) - if this part is present, the count with groupBy doesnt gives 1 as value for Nulls.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77f655f",
   "metadata": {},
   "source": [
    "## In the above, if there are no enrolments(i.e null values), then count should return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5dc89a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum,when,expr\n",
    "\n",
    "# # \"when\" can be use in functions like select,agg,sum,min,orderBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d29be290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+\n",
      "|user_id|course_count|\n",
      "+-------+------------+\n",
      "|      1|           0|\n",
      "|      2|           0|\n",
      "|      3|           2|\n",
      "|      4|           2|\n",
      "|      5|           3|\n",
      "|      6|           0|\n",
      "|      7|           3|\n",
      "|      8|           3|\n",
      "|      9|           1|\n",
      "|     10|           1|\n",
      "+-------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# agg method works on each group\n",
    "\n",
    "users_df.alias('u'). \\\n",
    "    join(course_enrolments_df.alias('ce'), users_df.user_id == course_enrolments_df.user_id, 'left'). \\\n",
    "    groupBy('u.user_id'). \\\n",
    "    agg(sum(when(course_enrolments_df['course_enrolment_id'].isNull(), 0).otherwise(1)).alias('course_count')). \\\n",
    "    orderBy('u.user_id'). \\\n",
    "    show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e8677eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# course_enrolments_df.\\\n",
    "#    select( sum(when(course_enrolments_df['course_enrolment_id'].isNull(), 0).otherwise(1).alias('course_count'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f80463d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------------------------------------------------+\n",
      "|user_id|sum(CASE WHEN (course_enrolment_id IS NULL) THEN 0 ELSE 1 END)|\n",
      "+-------+--------------------------------------------------------------+\n",
      "|      1|                                                             0|\n",
      "|      2|                                                             0|\n",
      "|      3|                                                             2|\n",
      "|      4|                                                             2|\n",
      "|      5|                                                             3|\n",
      "|      6|                                                             0|\n",
      "|      7|                                                             3|\n",
      "|      8|                                                             3|\n",
      "|      9|                                                             1|\n",
      "|     10|                                                             1|\n",
      "+-------+--------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL TYPE SYNTAX\n",
    "\n",
    "users_df.alias('u'). \\\n",
    "    join(course_enrolments_df.alias('ce'), users_df.user_id == course_enrolments_df.user_id, 'left'). \\\n",
    "    groupBy('u.user_id'). \\\n",
    "    agg(sum(expr(\"\"\"\n",
    "            \n",
    "            CASE when course_enrolment_id is null\n",
    "                    then 0\n",
    "            ELSE 1\n",
    "            END\n",
    "    \n",
    "    \"\"\"\n",
    "))).show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5235cc60",
   "metadata": {},
   "source": [
    "# Performing Right/rightouter/right_outer join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5eceb478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+---------+----------+---------------+--------------+--------------------+\n",
      "|user_id|course_enrolment_id|course_id|price_paid|user_first_name|user_last_name|          user_email|\n",
      "+-------+-------------------+---------+----------+---------------+--------------+--------------------+\n",
      "|      1|               null|     null|      null|         Sandra|        Karpov|    skarpov0@ovh.net|\n",
      "|      2|               null|     null|      null|           Kari|        Dearth|kdearth1@so-net.n...|\n",
      "|      3|                 10|        3|     10.99|         Joanna|      Spennock|jspennock2@redcro...|\n",
      "|      3|                 12|        2|      9.99|         Joanna|      Spennock|jspennock2@redcro...|\n",
      "|      4|                  7|        5|     10.99|         Hirsch|       Conaboy|hconaboy3@barnesa...|\n",
      "|      4|                 14|        3|     10.99|         Hirsch|       Conaboy|hconaboy3@barnesa...|\n",
      "|      5|                  2|        2|      9.99|         Loreen|         Malin|lmalin4@independe...|\n",
      "|      5|                  6|        5|     10.99|         Loreen|         Malin|lmalin4@independe...|\n",
      "|      5|                 13|        2|      9.99|         Loreen|         Malin|lmalin4@independe...|\n",
      "|      6|               null|     null|      null|           Augy|      Christon|  achriston5@mlb.com|\n",
      "|      7|                  3|        5|     10.99|         Trudey|       Choupin|     tchoupin6@de.vu|\n",
      "|      7|                  8|        3|     10.99|         Trudey|       Choupin|     tchoupin6@de.vu|\n",
      "|      7|                 11|        5|     10.99|         Trudey|       Choupin|     tchoupin6@de.vu|\n",
      "|      8|                  5|        2|      9.99|         Nadine|     Grimsdell|ngrimsdell7@sohu.com|\n",
      "|      8|                  9|        5|     10.99|         Nadine|     Grimsdell|ngrimsdell7@sohu.com|\n",
      "|      8|                 15|        2|      9.99|         Nadine|     Grimsdell|ngrimsdell7@sohu.com|\n",
      "|      9|                  4|        2|      9.99|        Vassily|         Tamas|vtamas8@businessw...|\n",
      "|     10|                  1|        2|      9.99|          Wells|      Simpkins|wsimpkins9@amazon...|\n",
      "+-------+-------------------+---------+----------+---------------+--------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "course_enrolments_df. \\\n",
    "    join(users_df, 'user_id', 'right'). \\\n",
    "    show()\n",
    "\n",
    "# or\n",
    "\n",
    "\n",
    "# course_enrolments_df. \\\n",
    "#     join(users_df, users_df.user_id == course_enrolments_df.user_id, 'right'). \\\n",
    "#     select(users_df['*'], course_enrolments_df['course_id'], course_enrolments_df['course_enrolment_id']). \\\n",
    "#     show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ea2650",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca88be4a",
   "metadata": {},
   "source": [
    "## Full outer Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d14fc081",
   "metadata": {},
   "outputs": [],
   "source": [
    "users1 = [\n",
    "    {\n",
    "        \"email\":\"alovett0@nsw.gov.au\",\n",
    "        \"first_name\":\"Aundrea\",\n",
    "        \"last_name\":\"Lovett\",\n",
    "        \"gender\":\"Male\",\n",
    "        \"ip_address\":\"62.72.1.143\"\n",
    "    },\n",
    "    {\n",
    "        \"email\":\"bjowling1@spiegel.de\",\n",
    "        \"first_name\":\"Bettine\",\n",
    "        \"last_name\":\"Jowling\",\n",
    "        \"gender\":\"Female\",\n",
    "        \"ip_address\":\"26.250.197.47\"\n",
    "    },\n",
    "    {\n",
    "        \"email\":\"rablitt2@technorati.com\",\n",
    "        \"first_name\":\"Reggie\",\n",
    "        \"last_name\":\"Ablitt\",\n",
    "        \"gender\":\"Male\",\n",
    "        \"ip_address\":\"104.181.218.238\"\n",
    "    },\n",
    "    {\n",
    "        \"email\":\"tgavahan3@printfriendly.com\",\n",
    "        \"first_name\":\"Ted\",\n",
    "        \"last_name\":\"Gavahan\",\n",
    "        \"gender\":\"Female\",\n",
    "        \"ip_address\":\"216.80.86.100\"\n",
    "    },\n",
    "    {\n",
    "        \"email\":\"ccastellan4@bloglovin.com\",\n",
    "        \"first_name\":\"Chantal\",\n",
    "        \"last_name\":\"Castellan\",\n",
    "        \"gender\":\"Female\",\n",
    "        \"ip_address\":\"178.93.82.145\"\n",
    "    },\n",
    "    {\n",
    "        \"email\":\"hcurrier5@hexun.com\",\n",
    "        \"first_name\":\"Herrick\",\n",
    "        \"last_name\":\"Currier\",\n",
    "        \"gender\":\"Male\",\n",
    "        \"ip_address\":\"98.120.5.78\"\n",
    "    },\n",
    "    {\n",
    "        \"email\":\"zlendrem6@columbia.edu\",\n",
    "        \"first_name\":\"Zorina\",\n",
    "        \"last_name\":\"Lendrem\",\n",
    "        \"gender\":\"Female\",\n",
    "        \"ip_address\":\"219.128.213.53\"\n",
    "    },\n",
    "    {\n",
    "        \"email\":\"lbutland7@time.com\",\n",
    "        \"first_name\":\"Lilas\",\n",
    "        \"last_name\":\"Butland\",\n",
    "        \"gender\":\"Female\",\n",
    "        \"ip_address\":\"109.110.131.151\"\n",
    "    },\n",
    "    {\n",
    "        \"email\":\"palfonsetti8@ask.com\",\n",
    "        \"first_name\":\"Putnam\",\n",
    "        \"last_name\":\"Alfonsetti\",\n",
    "        \"gender\":\"Female\",\n",
    "        \"ip_address\":\"167.97.48.246\"\n",
    "    },\n",
    "    {\n",
    "        \"email\":\"hunitt9@bizjournals.com\",\n",
    "        \"first_name\":\"Holden\",\n",
    "        \"last_name\":\"Unitt\",\n",
    "        \"gender\":\"Female\",\n",
    "        \"ip_address\":\"142.228.161.192\"\n",
    "    },\n",
    "    {\n",
    "        \"email\":\"dmcmorrana@reference.com\",\n",
    "        \"first_name\":\"Dorice\",\n",
    "        \"last_name\":\"McMorran\",\n",
    "        \"gender\":\"Female\",\n",
    "        \"ip_address\":\"233.1.28.220\"\n",
    "    },\n",
    "    {\n",
    "        \"email\":\"afaulconerb@barnesandnoble.com\",\n",
    "        \"first_name\":\"Andris\",\n",
    "        \"last_name\":\"Faulconer\",\n",
    "        \"gender\":\"Female\",\n",
    "        \"ip_address\":\"109.40.175.103\"\n",
    "    },\n",
    "    {\n",
    "        \"email\":\"kupexc@sun.com\",\n",
    "        \"first_name\":\"Krispin\",\n",
    "        \"last_name\":\"Upex\",\n",
    "        \"gender\":\"Male\",\n",
    "        \"ip_address\":\"154.110.22.75\"\n",
    "    },\n",
    "    {\n",
    "        \"email\":\"fmancktelowd@youku.com\",\n",
    "        \"first_name\":\"Farand\",\n",
    "        \"last_name\":\"Mancktelow\",\n",
    "        \"gender\":\"Genderqueer\",\n",
    "        \"ip_address\":\"190.20.187.10\"\n",
    "    },\n",
    "    {\n",
    "        \"email\":\"kdodgshune@google.com\",\n",
    "        \"first_name\":\"Kellyann\",\n",
    "        \"last_name\":\"Dodgshun\",\n",
    "        \"gender\":\"Female\",\n",
    "        \"ip_address\":\"80.247.105.228\"\n",
    "    }\n",
    "]\n",
    "\n",
    "from pyspark.sql import Row\n",
    "users1_df = spark.createDataFrame([Row(**user) for user in users1])\n",
    "     \n",
    "\n",
    "users2 = [{\n",
    "        \"email\":\"lbutland7@time.com\",\n",
    "        \"first_name\":\"Lilas\",\n",
    "        \"last_name\":\"Butland\",\n",
    "        \"gender\":\"Female\",\n",
    "        \"ip_address\":\"109.110.131.151\"\n",
    "    },\n",
    "    {\n",
    "        \"email\":\"palfonsetti8@ask.com\",\n",
    "        \"first_name\":\"Putnam\",\n",
    "        \"last_name\":\"Alfonsetti\",\n",
    "        \"gender\":\"Female\",\n",
    "        \"ip_address\":\"167.97.48.246\"\n",
    "    },\n",
    "    {\n",
    "        \"email\":\"hunitt9@bizjournals.com\",\n",
    "        \"first_name\":\"Holden\",\n",
    "        \"last_name\":\"Unitt\",\n",
    "        \"gender\":\"Female\",\n",
    "        \"ip_address\":\"142.228.161.192\"\n",
    "    },\n",
    "    {\n",
    "        \"email\":\"dmcmorrana@reference.com\",\n",
    "        \"first_name\":\"Dorice\",\n",
    "        \"last_name\":\"McMorran\",\n",
    "        \"gender\":\"Female\",\n",
    "        \"ip_address\":\"233.1.28.220\"\n",
    "    },\n",
    "    {\n",
    "        \"email\":\"afaulconerb@barnesandnoble.com\",\n",
    "        \"first_name\":\"Andris\",\n",
    "        \"last_name\":\"Faulconer\",\n",
    "        \"gender\":\"Female\",\n",
    "        \"ip_address\":\"109.40.175.103\"\n",
    "    },\n",
    "    {\n",
    "        \"email\":\"kupexc@sun.com\",\n",
    "        \"first_name\":\"Krispin\",\n",
    "        \"last_name\":\"Upex\",\n",
    "        \"gender\":\"Male\",\n",
    "        \"ip_address\":\"154.110.22.75\"\n",
    "    },\n",
    "    {\n",
    "        \"email\":\"fmancktelowd@youku.com\",\n",
    "        \"first_name\":\"Farand\",\n",
    "        \"last_name\":\"Mancktelow\",\n",
    "        \"gender\":\"Genderqueer\",\n",
    "        \"ip_address\":\"190.20.187.10\"\n",
    "    },\n",
    "    {\n",
    "        \"email\":\"kdodgshune@google.com\",\n",
    "        \"first_name\":\"Kellyann\",\n",
    "        \"last_name\":\"Dodgshun\",\n",
    "        \"gender\":\"Female\",\n",
    "        \"ip_address\":\"80.247.105.228\"\n",
    "    },\n",
    "    {\n",
    "        \"email\":\"kbaressf@geocities.jp\",\n",
    "        \"first_name\":\"Karly\",\n",
    "        \"last_name\":\"Baress\",\n",
    "        \"gender\":\"Female\",\n",
    "        \"ip_address\":\"145.232.153.145\"\n",
    "    },\n",
    "    {\n",
    "        \"email\":\"amillinsg@com.com\",\n",
    "        \"first_name\":\"Adelaide\",\n",
    "        \"last_name\":\"Millins\",\n",
    "        \"gender\":\"Female\",\n",
    "        \"ip_address\":\"75.160.220.182\"\n",
    "    },\n",
    "    {\n",
    "        \"email\":\"skemsleyh@quantcast.com\",\n",
    "        \"first_name\":\"Shir\",\n",
    "        \"last_name\":\"Kemsley\",\n",
    "        \"gender\":\"Male\",\n",
    "        \"ip_address\":\"234.195.73.177\"\n",
    "    },\n",
    "    {\n",
    "        \"email\":\"kchomiszewskii@simplemachines.org\",\n",
    "        \"first_name\":\"Kristo\",\n",
    "        \"last_name\":\"Chomiszewski\",\n",
    "        \"gender\":\"Female\",\n",
    "        \"ip_address\":\"60.91.73.198\"\n",
    "    },\n",
    "    {\n",
    "        \"email\":\"rkelwickj@baidu.com\",\n",
    "        \"first_name\":\"Rosemonde\",\n",
    "        \"last_name\":\"Kelwick\",\n",
    "        \"gender\":\"Genderfluid\",\n",
    "        \"ip_address\":\"42.50.134.65\"\n",
    "    }\n",
    "]\n",
    "\n",
    "from pyspark.sql import Row\n",
    "users2_df = spark.createDataFrame([Row(**user) for user in users2])\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "842aa58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+---------+------+--------------+--------------------+----------+---------+------+--------------+\n",
      "|               email|first_name|last_name|gender|    ip_address|               email|first_name|last_name|gender|    ip_address|\n",
      "+--------------------+----------+---------+------+--------------+--------------------+----------+---------+------+--------------+\n",
      "|afaulconerb@barne...|    Andris|Faulconer|Female|109.40.175.103|afaulconerb@barne...|    Andris|Faulconer|Female|109.40.175.103|\n",
      "| alovett0@nsw.gov.au|   Aundrea|   Lovett|  Male|   62.72.1.143|                null|      null|     null|  null|          null|\n",
      "|                null|      null|     null|  null|          null|   amillinsg@com.com|  Adelaide|  Millins|Female|75.160.220.182|\n",
      "|bjowling1@spiegel.de|   Bettine|  Jowling|Female| 26.250.197.47|                null|      null|     null|  null|          null|\n",
      "|ccastellan4@blogl...|   Chantal|Castellan|Female| 178.93.82.145|                null|      null|     null|  null|          null|\n",
      "|dmcmorrana@refere...|    Dorice| McMorran|Female|  233.1.28.220|dmcmorrana@refere...|    Dorice| McMorran|Female|  233.1.28.220|\n",
      "+--------------------+----------+---------+------+--------------+--------------------+----------+---------+------+--------------+\n",
      "only showing top 6 rows\n",
      "\n",
      "+--------------------+----------+---------+------+--------------+----------+---------+------+--------------+\n",
      "|               email|first_name|last_name|gender|    ip_address|first_name|last_name|gender|    ip_address|\n",
      "+--------------------+----------+---------+------+--------------+----------+---------+------+--------------+\n",
      "|kdodgshune@google...|  Kellyann| Dodgshun|Female|80.247.105.228|  Kellyann| Dodgshun|Female|80.247.105.228|\n",
      "+--------------------+----------+---------+------+--------------+----------+---------+------+--------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# outer or full or fullouter or full_outer are same\n",
    "\n",
    "users1_df. \\\n",
    "    join(users2_df, users1_df.email == users2_df.email, 'full'). \\\n",
    "    show(6)\n",
    "\n",
    "# it is the union of both tables\n",
    "\n",
    "# users1_df. \\\n",
    "#     join(users2_df, \"email\", 'full'). \\\n",
    "#     show()\n",
    "\n",
    "\n",
    "# The full outer join is union of left and right outer joins\n",
    "# we get duplicates in below method\n",
    "\n",
    "users1_df. \\\n",
    "    join(users2_df, 'email', 'left'). \\\n",
    "    union(\n",
    "        users1_df. \\\n",
    "            join(users2_df, 'email', 'right')\n",
    "    ). \\\n",
    "    distinct(). \\\n",
    "    show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b3fdd0",
   "metadata": {},
   "source": [
    "# coalesce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ffe80123",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Projecting data after full outer join\n",
    "# Get the details from the users1_df, if missing get details from users2_df\n",
    "\n",
    "from pyspark.sql.functions import coalesce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7eb39b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function coalesce in module pyspark.sql.functions:\n",
      "\n",
      "coalesce(*cols)\n",
      "    Returns the first column that is not null.\n",
      "    \n",
      "    .. versionadded:: 1.4.0\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> cDf = spark.createDataFrame([(None, None), (1, None), (None, 2)], (\"a\", \"b\"))\n",
      "    >>> cDf.show()\n",
      "    +----+----+\n",
      "    |   a|   b|\n",
      "    +----+----+\n",
      "    |null|null|\n",
      "    |   1|null|\n",
      "    |null|   2|\n",
      "    +----+----+\n",
      "    \n",
      "    >>> cDf.select(coalesce(cDf[\"a\"], cDf[\"b\"])).show()\n",
      "    +--------------+\n",
      "    |coalesce(a, b)|\n",
      "    +--------------+\n",
      "    |          null|\n",
      "    |             1|\n",
      "    |             2|\n",
      "    +--------------+\n",
      "    \n",
      "    >>> cDf.select('*', coalesce(cDf[\"a\"], lit(0.0))).show()\n",
      "    +----+----+----------------+\n",
      "    |   a|   b|coalesce(a, 0.0)|\n",
      "    +----+----+----------------+\n",
      "    |null|null|             0.0|\n",
      "    |   1|null|             1.0|\n",
      "    |null|   2|             0.0|\n",
      "    +----+----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(coalesce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c123f723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+------------+-----------+---------------+\n",
      "|               email|first_name|   last_name|     gender|     ip_address|\n",
      "+--------------------+----------+------------+-----------+---------------+\n",
      "|afaulconerb@barne...|    Andris|   Faulconer|     Female| 109.40.175.103|\n",
      "| alovett0@nsw.gov.au|   Aundrea|      Lovett|       Male|    62.72.1.143|\n",
      "|   amillinsg@com.com|  Adelaide|     Millins|     Female| 75.160.220.182|\n",
      "|bjowling1@spiegel.de|   Bettine|     Jowling|     Female|  26.250.197.47|\n",
      "|ccastellan4@blogl...|   Chantal|   Castellan|     Female|  178.93.82.145|\n",
      "|dmcmorrana@refere...|    Dorice|    McMorran|     Female|   233.1.28.220|\n",
      "|fmancktelowd@youk...|    Farand|  Mancktelow|Genderqueer|  190.20.187.10|\n",
      "| hcurrier5@hexun.com|   Herrick|     Currier|       Male|    98.120.5.78|\n",
      "|hunitt9@bizjourna...|    Holden|       Unitt|     Female|142.228.161.192|\n",
      "|kbaressf@geocitie...|     Karly|      Baress|     Female|145.232.153.145|\n",
      "|kchomiszewskii@si...|    Kristo|Chomiszewski|     Female|   60.91.73.198|\n",
      "|kdodgshune@google...|  Kellyann|    Dodgshun|     Female| 80.247.105.228|\n",
      "|      kupexc@sun.com|   Krispin|        Upex|       Male|  154.110.22.75|\n",
      "|  lbutland7@time.com|     Lilas|     Butland|     Female|109.110.131.151|\n",
      "|palfonsetti8@ask.com|    Putnam|  Alfonsetti|     Female|  167.97.48.246|\n",
      "|rablitt2@technora...|    Reggie|      Ablitt|       Male|104.181.218.238|\n",
      "| rkelwickj@baidu.com| Rosemonde|     Kelwick|Genderfluid|   42.50.134.65|\n",
      "|skemsleyh@quantca...|      Shir|     Kemsley|       Male| 234.195.73.177|\n",
      "|tgavahan3@printfr...|       Ted|     Gavahan|     Female|  216.80.86.100|\n",
      "|zlendrem6@columbi...|    Zorina|     Lendrem|     Female| 219.128.213.53|\n",
      "+--------------------+----------+------------+-----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Projecting data after full outer join\n",
    "# Get the details from the users1_df, if missing get details from users2_df\n",
    "\n",
    "from pyspark.sql.functions import coalesce\n",
    "users1_df. \\\n",
    "    join(users2_df, users1_df.email == users2_df.email, 'full'). \\\n",
    "    select(\n",
    "        coalesce(users1_df['email'], users2_df['email']).alias('email'),\n",
    "        coalesce(users1_df['first_name'], users2_df['first_name']).alias('first_name'),\n",
    "        coalesce(users1_df['last_name'], users2_df['last_name']).alias('last_name'),\n",
    "        coalesce(users1_df['gender'], users2_df['gender']).alias('gender'),\n",
    "        coalesce(users1_df['ip_address'], users2_df['ip_address']).alias('ip_address'),\n",
    "    ). \\\n",
    "    show()\n",
    "\n",
    "# if email in users1_df is Null, then it takes values from users2_df\n",
    "# similarly for other columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc904aa",
   "metadata": {},
   "source": [
    "# Broadcast join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "033a3eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is also known as map side as well as replicated join.\n",
    "\n",
    "# The smaller data set will be broadcasted to all the executors in the cluster.\n",
    "\n",
    "# The size of the smaller data set is driven by spark.sql.autoBroadcastJoinThreshold.\n",
    "\n",
    "# We can even perform broadcast join when the smaller data set size is greater than spark.sql.autoBroadcastJoinThreshold by using broadcast function from pyspark.sql.functions.\n",
    "\n",
    "# We can disable broadcast join by setting spark.sql.autoBroadcastJoinThreshold value to 0.\n",
    "\n",
    "# If broadcast join is disabled then it will result in reduce side join.\n",
    "\n",
    "# Make sure to setup multinode cluster using 28 GB Memory, 4 Cores each. Configure scaling between 2 and 4 nodes. Driver can be of minimum configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4523f19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd03934",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a84ddb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a00c81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b4582e0",
   "metadata": {},
   "source": [
    "## Cross Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "eb1b4600",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df.crossJoin(courses_df).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ef3cdcc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method crossJoin in module pyspark.sql.dataframe:\n",
      "\n",
      "crossJoin(other) method of pyspark.sql.dataframe.DataFrame instance\n",
      "    Returns the cartesian product with another :class:`DataFrame`.\n",
      "    \n",
      "    .. versionadded:: 2.1.0\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    other : :class:`DataFrame`\n",
      "        Right side of the cartesian product.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df.select(\"age\", \"name\").collect()\n",
      "    [Row(age=2, name='Alice'), Row(age=5, name='Bob')]\n",
      "    >>> df2.select(\"name\", \"height\").collect()\n",
      "    [Row(name='Tom', height=80), Row(name='Bob', height=85)]\n",
      "    >>> df.crossJoin(df2.select(\"height\")).select(\"age\", \"name\", \"height\").collect()\n",
      "    [Row(age=2, name='Alice', height=80), Row(age=2, name='Alice', height=85),\n",
      "     Row(age=5, name='Bob', height=80), Row(age=5, name='Bob', height=85)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(users_df.crossJoin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d3bdfa75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df.join(courses_df).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bca0daac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method join in module pyspark.sql.dataframe:\n",
      "\n",
      "join(other, on=None, how=None) method of pyspark.sql.dataframe.DataFrame instance\n",
      "    Joins with another :class:`DataFrame`, using the given join expression.\n",
      "    \n",
      "    .. versionadded:: 1.3.0\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    other : :class:`DataFrame`\n",
      "        Right side of the join\n",
      "    on : str, list or :class:`Column`, optional\n",
      "        a string for the join column name, a list of column names,\n",
      "        a join expression (Column), or a list of Columns.\n",
      "        If `on` is a string or a list of strings indicating the name of the join column(s),\n",
      "        the column(s) must exist on both sides, and this performs an equi-join.\n",
      "    how : str, optional\n",
      "        default ``inner``. Must be one of: ``inner``, ``cross``, ``outer``,\n",
      "        ``full``, ``fullouter``, ``full_outer``, ``left``, ``leftouter``, ``left_outer``,\n",
      "        ``right``, ``rightouter``, ``right_outer``, ``semi``, ``leftsemi``, ``left_semi``,\n",
      "        ``anti``, ``leftanti`` and ``left_anti``.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    The following performs a full outer join between ``df1`` and ``df2``.\n",
      "    \n",
      "    >>> from pyspark.sql.functions import desc\n",
      "    >>> df.join(df2, df.name == df2.name, 'outer').select(df.name, df2.height)                 .sort(desc(\"name\")).collect()\n",
      "    [Row(name='Bob', height=85), Row(name='Alice', height=None), Row(name=None, height=80)]\n",
      "    \n",
      "    >>> df.join(df2, 'name', 'outer').select('name', 'height').sort(desc(\"name\")).collect()\n",
      "    [Row(name='Tom', height=80), Row(name='Bob', height=85), Row(name='Alice', height=None)]\n",
      "    \n",
      "    >>> cond = [df.name == df3.name, df.age == df3.age]\n",
      "    >>> df.join(df3, cond, 'outer').select(df.name, df3.age).collect()\n",
      "    [Row(name='Alice', age=2), Row(name='Bob', age=5)]\n",
      "    \n",
      "    >>> df.join(df2, 'name').select(df.name, df2.height).collect()\n",
      "    [Row(name='Bob', height=85)]\n",
      "    \n",
      "    >>> df.join(df4, ['name', 'age']).select(df.name, df.age).collect()\n",
      "    [Row(name='Bob', age=5)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(users_df.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23218331",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
