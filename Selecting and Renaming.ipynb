{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebfbd96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31bc3941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "users = [\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"first_name\": \"Corrie\",\n",
    "        \"last_name\": \"Van den Oord\",\n",
    "        \"email\": \"cvandenoord0@etsy.com\",\n",
    "        \"phone_numbers\": Row(mobile=\"+1 234 567 8901\", home=\"+1 234 567 8911\"),\n",
    "        \"courses\": [1, 2],\n",
    "        \"is_customer\": True,\n",
    "        \"amount_paid\": 1000.55,\n",
    "        \"customer_from\": datetime.date(2021, 1, 15),\n",
    "        \"last_updated_ts\": datetime.datetime(2021, 2, 10, 1, 15, 0)\n",
    "    },\n",
    "    {\n",
    "        \"id\": 2,\n",
    "        \"first_name\": \"Nikolaus\",\n",
    "        \"last_name\": \"Brewitt\",\n",
    "        \"email\": \"nbrewitt1@dailymail.co.uk\",\n",
    "        \"phone_numbers\":  Row(mobile=\"+1 234 567 8923\", home=\"1 234 567 8934\"),\n",
    "        \"courses\": [3],\n",
    "        \"is_customer\": True,\n",
    "        \"amount_paid\": 900.0,\n",
    "        \"customer_from\": datetime.date(2021, 2, 14),\n",
    "        \"last_updated_ts\": datetime.datetime(2021, 2, 18, 3, 33, 0)\n",
    "    },\n",
    "    {\n",
    "        \"id\": 3,\n",
    "        \"first_name\": \"Orelie\",\n",
    "        \"last_name\": \"Penney\",\n",
    "        \"email\": \"openney2@vistaprint.com\",\n",
    "        \"phone_numbers\": Row(mobile=\"+1 714 512 9752\", home=\"+1 714 512 6601\"),\n",
    "        \"courses\": [2, 4],\n",
    "        \"is_customer\": True,\n",
    "        \"amount_paid\": 850.55,\n",
    "        \"customer_from\": datetime.date(2021, 1, 21),\n",
    "        \"last_updated_ts\": datetime.datetime(2021, 3, 15, 15, 16, 55)\n",
    "    },\n",
    "    {\n",
    "        \"id\": 4,\n",
    "        \"first_name\": \"Ashby\",\n",
    "        \"last_name\": \"Maddocks\",\n",
    "        \"email\": \"amaddocks3@home.pl\",\n",
    "        \"phone_numbers\": Row(mobile=None, home=None),\n",
    "        \"courses\": [],\n",
    "        \"is_customer\": False,\n",
    "        \"amount_paid\": None,\n",
    "        \"customer_from\": None,\n",
    "        \"last_updated_ts\": datetime.datetime(2021, 4, 10, 17, 45, 30)\n",
    "    },\n",
    "    {\n",
    "        \"id\": 5,\n",
    "        \"first_name\": \"Kurt\",\n",
    "        \"last_name\": \"Rome\",\n",
    "        \"email\": \"krome4@shutterfly.com\",\n",
    "        \"phone_numbers\": Row(mobile=\"+1 817 934 7142\", home=None),\n",
    "        \"courses\": [],\n",
    "        \"is_customer\": False,\n",
    "        \"amount_paid\": None,\n",
    "        \"customer_from\": None,\n",
    "        \"last_updated_ts\": datetime.datetime(2021, 4, 2, 0, 55, 18)\n",
    "    }\n",
    "]\n",
    "\n",
    "# the courses(list) column converted to Array in Spark DataFrame\n",
    "# The phone_numbers(Row) column converted to Struct in Spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fb9ef59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrow is available as an optimization when converting Spark Data Frames to and from Pandas Data Frames.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\",False)\n",
    "\n",
    "users_df = spark.createDataFrame(pd.DataFrame(users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fd1f05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------------+--------------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n",
      "| id|first_name|   last_name|               email|       phone_numbers|courses|is_customer|amount_paid|customer_from|    last_updated_ts|\n",
      "+---+----------+------------+--------------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n",
      "|  1|    Corrie|Van den Oord|cvandenoord0@etsy...|{+1 234 567 8901,...| [1, 2]|       true|    1000.55|   2021-01-15|2021-02-10 01:15:00|\n",
      "|  2|  Nikolaus|     Brewitt|nbrewitt1@dailyma...|{+1 234 567 8923,...|    [3]|       true|      900.0|   2021-02-14|2021-02-18 03:33:00|\n",
      "|  3|    Orelie|      Penney|openney2@vistapri...|{+1 714 512 9752,...| [2, 4]|       true|     850.55|   2021-01-21|2021-03-15 15:16:55|\n",
      "|  4|     Ashby|    Maddocks|  amaddocks3@home.pl|        {null, null}|     []|      false|        NaN|         null|2021-04-10 17:45:30|\n",
      "|  5|      Kurt|        Rome|krome4@shutterfly...|{+1 817 934 7142,...|     []|      false|        NaN|         null|2021-04-02 00:55:18|\n",
      "+---+----------+------------+--------------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "users_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4aee8567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- phone_numbers: struct (nullable = true)\n",
      " |    |-- mobile: string (nullable = true)\n",
      " |    |-- home: string (nullable = true)\n",
      " |-- courses: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- is_customer: boolean (nullable = true)\n",
      " |-- amount_paid: double (nullable = true)\n",
      " |-- customer_from: date (nullable = true)\n",
      " |-- last_updated_ts: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a3dc8f",
   "metadata": {},
   "source": [
    "## Overview of Narrow and wide transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3df9571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference - https://www.databricks.com/glossary/what-are-transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43015745",
   "metadata": {},
   "source": [
    "* Here are the functions related to narrow transformations. Narrow transformations doesn't result in shuffling. These are also known as row level transformations.\n",
    "    * df.select\n",
    "    * df.filter\n",
    "    * df.withColumn\n",
    "    * df.withColumnRenamed\n",
    "    * df.drop\n",
    "* Here are the functions related to wide transformations.\n",
    "    * df.distinct\n",
    "    * df.union or any set operation\n",
    "    * df.join or any join operation\n",
    "    * df.groupBy\n",
    "    * df.sort or df.orderBy\n",
    "* Any function that result in shuffling is wide transformation. For all the wide transformations, we have to deal with group of records based on a key."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8072243",
   "metadata": {},
   "source": [
    "## Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a8780e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method select in module pyspark.sql.dataframe:\n",
      "\n",
      "select(*cols) method of pyspark.sql.dataframe.DataFrame instance\n",
      "    Projects a set of expressions and returns a new :class:`DataFrame`.\n",
      "    \n",
      "    .. versionadded:: 1.3.0\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    cols : str, :class:`Column`, or list\n",
      "        column names (string) or expressions (:class:`Column`).\n",
      "        If one of the column names is '*', that column is expanded to include all columns\n",
      "        in the current :class:`DataFrame`.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df.select('*').collect()\n",
      "    [Row(age=2, name='Alice'), Row(age=5, name='Bob')]\n",
      "    >>> df.select('name', 'age').collect()\n",
      "    [Row(name='Alice', age=2), Row(name='Bob', age=5)]\n",
      "    >>> df.select(df.name, (df.age + 10).alias('age')).collect()\n",
      "    [Row(name='Alice', age=12), Row(name='Bob', age=15)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(users_df.select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "895059cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------------+--------------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n",
      "| id|first_name|   last_name|               email|       phone_numbers|courses|is_customer|amount_paid|customer_from|    last_updated_ts|\n",
      "+---+----------+------------+--------------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n",
      "|  1|    Corrie|Van den Oord|cvandenoord0@etsy...|{+1 234 567 8901,...| [1, 2]|       true|    1000.55|   2021-01-15|2021-02-10 01:15:00|\n",
      "|  2|  Nikolaus|     Brewitt|nbrewitt1@dailyma...|{+1 234 567 8923,...|    [3]|       true|      900.0|   2021-02-14|2021-02-18 03:33:00|\n",
      "|  3|    Orelie|      Penney|openney2@vistapri...|{+1 714 512 9752,...| [2, 4]|       true|     850.55|   2021-01-21|2021-03-15 15:16:55|\n",
      "|  4|     Ashby|    Maddocks|  amaddocks3@home.pl|        {null, null}|     []|      false|        NaN|         null|2021-04-10 17:45:30|\n",
      "|  5|      Kurt|        Rome|krome4@shutterfly...|{+1 817 934 7142,...|     []|      false|        NaN|         null|2021-04-02 00:55:18|\n",
      "+---+----------+------------+--------------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_df.select(\"*\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a36b6e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------------+\n",
      "| id|first_name|   last_name|\n",
      "+---+----------+------------+\n",
      "|  1|    Corrie|Van den Oord|\n",
      "|  2|  Nikolaus|     Brewitt|\n",
      "|  3|    Orelie|      Penney|\n",
      "|  4|     Ashby|    Maddocks|\n",
      "|  5|      Kurt|        Rome|\n",
      "+---+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_df.select(\"id\",\"first_name\",\"last_name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82ce3a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------------+\n",
      "| id|first_name|   last_name|\n",
      "+---+----------+------------+\n",
      "|  1|    Corrie|Van den Oord|\n",
      "|  2|  Nikolaus|     Brewitt|\n",
      "|  3|    Orelie|      Penney|\n",
      "|  4|     Ashby|    Maddocks|\n",
      "|  5|      Kurt|        Rome|\n",
      "+---+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# list of strings\n",
    "users_df.select([\"id\",\"first_name\",\"last_name\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af679084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------------+--------------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n",
      "| id|first_name|   last_name|               email|       phone_numbers|courses|is_customer|amount_paid|customer_from|    last_updated_ts|\n",
      "+---+----------+------------+--------------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n",
      "|  1|    Corrie|Van den Oord|cvandenoord0@etsy...|{+1 234 567 8901,...| [1, 2]|       true|    1000.55|   2021-01-15|2021-02-10 01:15:00|\n",
      "|  2|  Nikolaus|     Brewitt|nbrewitt1@dailyma...|{+1 234 567 8923,...|    [3]|       true|      900.0|   2021-02-14|2021-02-18 03:33:00|\n",
      "|  3|    Orelie|      Penney|openney2@vistapri...|{+1 714 512 9752,...| [2, 4]|       true|     850.55|   2021-01-21|2021-03-15 15:16:55|\n",
      "|  4|     Ashby|    Maddocks|  amaddocks3@home.pl|        {null, null}|     []|      false|        NaN|         null|2021-04-10 17:45:30|\n",
      "|  5|      Kurt|        Rome|krome4@shutterfly...|{+1 817 934 7142,...|     []|      false|        NaN|         null|2021-04-02 00:55:18|\n",
      "+---+----------+------------+--------------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Defining alias to dataframe\n",
    "\n",
    "# we can use drop,select, join and other funcs with use of aliases \n",
    "\n",
    "users_df.alias(\"u\").select(\"u.*\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "13cc2334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-------------------------+\n",
      "|id |first_name|email                    |\n",
      "+---+----------+-------------------------+\n",
      "|1  |Corrie    |cvandenoord0@etsy.com    |\n",
      "|2  |Nikolaus  |nbrewitt1@dailymail.co.uk|\n",
      "|3  |Orelie    |openney2@vistaprint.com  |\n",
      "|4  |Ashby     |amaddocks3@home.pl       |\n",
      "|5  |Kurt      |krome4@shutterfly.com    |\n",
      "+---+----------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_df.alias(\"u\").select(\"u.id\",\"u.first_name\",\"u.email\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "616c3f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# col - Returns a Column based on the given column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "248cea75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------------+\n",
      "| id|first_name|               email|\n",
      "+---+----------+--------------------+\n",
      "|  1|    Corrie|cvandenoord0@etsy...|\n",
      "|  2|  Nikolaus|nbrewitt1@dailyma...|\n",
      "|  3|    Orelie|openney2@vistapri...|\n",
      "|  4|     Ashby|  amaddocks3@home.pl|\n",
      "|  5|      Kurt|krome4@shutterfly...|\n",
      "+---+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# We can use col(column name)[ this returns a column] with column strings .\n",
    "\n",
    "users_df.select(col(\"id\"),\"first_name\",\"email\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5caf93e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------------+---+--------------------+\n",
      "|id |first_name|last_name   |id |full_name           |\n",
      "+---+----------+------------+---+--------------------+\n",
      "|1  |Corrie    |Van den Oord|1  |Corrie, Van den Oord|\n",
      "|2  |Nikolaus  |Brewitt     |2  |Nikolaus, Brewitt   |\n",
      "|3  |Orelie    |Penney      |3  |Orelie, Penney      |\n",
      "|4  |Ashby     |Maddocks    |4  |Ashby, Maddocks     |\n",
      "|5  |Kurt      |Rome        |5  |Kurt, Rome          |\n",
      "+---+----------+------------+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col,concat,lit\n",
    "\n",
    "# lit ( literal )- add the new content \n",
    "# lit Reference - https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.lit.html?highlight=lit\n",
    "\n",
    "\n",
    "users_df.select(\n",
    "        col(\"id\"),\n",
    "        \"first_name\",\n",
    "        \"last_name\",\n",
    "        lit(col(\"id\")),\n",
    "         concat(\"first_name\",lit(\", \"),col(\"last_name\")).alias(\"full_name\")\n",
    "\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294dd3b2",
   "metadata": {},
   "source": [
    "## SelectExpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "898b3ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## here we use sql style syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "63eee170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method selectExpr in module pyspark.sql.dataframe:\n",
      "\n",
      "selectExpr(*expr) method of pyspark.sql.dataframe.DataFrame instance\n",
      "    Projects a set of SQL expressions and returns a new :class:`DataFrame`.\n",
      "    \n",
      "    This is a variant of :func:`select` that accepts SQL expressions.\n",
      "    \n",
      "    .. versionadded:: 1.3.0\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df.selectExpr(\"age * 2\", \"abs(age)\").collect()\n",
      "    [Row((age * 2)=4, abs(age)=2), Row((age * 2)=10, abs(age)=5)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(users_df.selectExpr)\n",
    "\n",
    "# selectExpr - uses only spark SQL expressions not the pyspark.sql functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b86e2192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------------+--------------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n",
      "| id|first_name|   last_name|               email|       phone_numbers|courses|is_customer|amount_paid|customer_from|    last_updated_ts|\n",
      "+---+----------+------------+--------------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n",
      "|  1|    Corrie|Van den Oord|cvandenoord0@etsy...|{+1 234 567 8901,...| [1, 2]|       true|    1000.55|   2021-01-15|2021-02-10 01:15:00|\n",
      "|  2|  Nikolaus|     Brewitt|nbrewitt1@dailyma...|{+1 234 567 8923,...|    [3]|       true|      900.0|   2021-02-14|2021-02-18 03:33:00|\n",
      "|  3|    Orelie|      Penney|openney2@vistapri...|{+1 714 512 9752,...| [2, 4]|       true|     850.55|   2021-01-21|2021-03-15 15:16:55|\n",
      "|  4|     Ashby|    Maddocks|  amaddocks3@home.pl|        {null, null}|     []|      false|        NaN|         null|2021-04-10 17:45:30|\n",
      "|  5|      Kurt|        Rome|krome4@shutterfly...|{+1 817 934 7142,...|     []|      false|        NaN|         null|2021-04-02 00:55:18|\n",
      "+---+----------+------------+--------------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_df.selectExpr(\"*\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "87eebe7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------------+--------------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n",
      "| id|first_name|   last_name|               email|       phone_numbers|courses|is_customer|amount_paid|customer_from|    last_updated_ts|\n",
      "+---+----------+------------+--------------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n",
      "|  1|    Corrie|Van den Oord|cvandenoord0@etsy...|{+1 234 567 8901,...| [1, 2]|       true|    1000.55|   2021-01-15|2021-02-10 01:15:00|\n",
      "|  2|  Nikolaus|     Brewitt|nbrewitt1@dailyma...|{+1 234 567 8923,...|    [3]|       true|      900.0|   2021-02-14|2021-02-18 03:33:00|\n",
      "|  3|    Orelie|      Penney|openney2@vistapri...|{+1 714 512 9752,...| [2, 4]|       true|     850.55|   2021-01-21|2021-03-15 15:16:55|\n",
      "|  4|     Ashby|    Maddocks|  amaddocks3@home.pl|        {null, null}|     []|      false|        NaN|         null|2021-04-10 17:45:30|\n",
      "|  5|      Kurt|        Rome|krome4@shutterfly...|{+1 817 934 7142,...|     []|      false|        NaN|         null|2021-04-02 00:55:18|\n",
      "+---+----------+------------+--------------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# alias with selectExpr\n",
    "\n",
    "users_df.alias(\"u\").selectExpr(\"u.*\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0232864b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------------+--------------------+\n",
      "| id|first_name|   last_name|           Full_Name|\n",
      "+---+----------+------------+--------------------+\n",
      "|  1|    Corrie|Van den Oord|Corrie, Van den Oord|\n",
      "|  2|  Nikolaus|     Brewitt|   Nikolaus, Brewitt|\n",
      "|  3|    Orelie|      Penney|      Orelie, Penney|\n",
      "|  4|     Ashby|    Maddocks|     Ashby, Maddocks|\n",
      "|  5|      Kurt|        Rome|          Kurt, Rome|\n",
      "+---+----------+------------+--------------------+\n",
      "\n",
      "+---+----------+------------+--------------------+\n",
      "| id|first_name|   last_name|           FULL_NAME|\n",
      "+---+----------+------------+--------------------+\n",
      "|  1|    Corrie|Van den Oord|Corrie, Van den Oord|\n",
      "|  2|  Nikolaus|     Brewitt|   Nikolaus, Brewitt|\n",
      "|  3|    Orelie|      Penney|      Orelie, Penney|\n",
      "|  4|     Ashby|    Maddocks|     Ashby, Maddocks|\n",
      "|  5|      Kurt|        Rome|          Kurt, Rome|\n",
      "+---+----------+------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "users_df.select(\n",
    "    \"id\",\n",
    "    \"first_name\",\n",
    "    \"last_name\",\n",
    "    concat(\"first_name\",lit(\", \"),col(\"last_name\")).alias(\"Full_Name\")\n",
    "\n",
    ").show()\n",
    "\n",
    "# in selectExpr , we have to use SQL Style syntax\n",
    "\n",
    "users_df.selectExpr(\n",
    "    \"id\",\n",
    "    \"first_name\",\n",
    "    \"last_name\",\n",
    "    'concat(first_name,\", \",last_name) AS FULL_NAME'\n",
    "\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1b9e298c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create Temporary View\n",
    "\n",
    "users_df.createOrReplaceTempView(\"users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7c242ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------------+--------------------+\n",
      "| id|first_name|   last_name|           full_name|\n",
      "+---+----------+------------+--------------------+\n",
      "|  1|    Corrie|Van den Oord|Corrie, Van den Oord|\n",
      "|  2|  Nikolaus|     Brewitt|   Nikolaus, Brewitt|\n",
      "|  3|    Orelie|      Penney|      Orelie, Penney|\n",
      "|  4|     Ashby|    Maddocks|     Ashby, Maddocks|\n",
      "|  5|      Kurt|        Rome|          Kurt, Rome|\n",
      "+---+----------+------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# SPARK SQL\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "    id,\n",
    "    first_name,\n",
    "    last_name,\n",
    "    concat(first_name,', ',last_name) AS full_name \n",
    "    FROM users\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da3e609",
   "metadata": {},
   "source": [
    "## Referring columns using spark dataframe names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1a9d7a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'(id = id)'>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df[\"id\"] == col(\"id\")\n",
    "\n",
    "# users_df[\"id\"] - returns a column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3df5d7a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.column.Column"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(users_df[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "5ba581a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+\n",
      "| id|first_name|\n",
      "+---+----------+\n",
      "|  1|    Corrie|\n",
      "|  2|  Nikolaus|\n",
      "|  3|    Orelie|\n",
      "|  4|     Ashby|\n",
      "|  5|      Kurt|\n",
      "+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_df.select(users_df[\"id\"],\"first_name\").show()\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "aa531bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'id'>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In PySpark, the alias method is used to assign an alias or alternative name to a DataFrame or column. However, \n",
    "# when using the indexing method (users_df[\"column_name\"]), it returns a Column object instead of a DataFrame. \n",
    "# The Column object does not have the alias method available, which is why u[\"id\"] or u[\"first_name\"] within the users_df.alias(\"u\").select(u[\"id\"],\"first_name\") statement will not work.\n",
    "\n",
    "# On the other hand, when you use the indexing method within the select statement with string literals (\"u.id\", \"u.first_name\"), PySpark treats them as column names rather than Column objects. \n",
    "# Thus, you can apply the alias method successfully on the column names, as shown in users_df.alias(\"u\").select(\"u.id\",\"u.first_name\").show()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1ed131e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+\n",
      "| id|first_name|\n",
      "+---+----------+\n",
      "|  1|    Corrie|\n",
      "|  2|  Nikolaus|\n",
      "|  3|    Orelie|\n",
      "|  4|     Ashby|\n",
      "|  5|      Kurt|\n",
      "+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# users_df.alias(\"u\").select(u[\"id\"],\"first_name\").show() will not work\n",
    "# aliases scope with indexing method ( u[\"id\"] ) will not be present in select expression\n",
    "\n",
    "\n",
    "users_df.alias(\"u\").select(\"u.id\",\"u.first_name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "556b8f8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Column is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7z/zf4v6y0d1q5bnv1v6p7tmvq80000gn/T/ipykernel_59948/41128223.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0musers_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselectExpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"first_name\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# it will not work as selectExpr accepts only the typical SQL Style syntaxs only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# col is pyspark.sql.function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mselectExpr\u001b[0;34m(self, *expr)\u001b[0m\n\u001b[1;32m   1700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1701\u001b[0m             \u001b[0mexpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1702\u001b[0;31m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselectExpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jseq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1703\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m_jseq\u001b[0;34m(self, cols, converter)\u001b[0m\n\u001b[1;32m   1426\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_jseq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m         \u001b[0;34m\"\"\"Return a JVM Seq of Columns from a list of Column or names\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1428\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_to_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_jmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pyspark/sql/column.py\u001b[0m in \u001b[0;36m_to_seq\u001b[0;34m(sc, cols, converter)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconverter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1313\u001b[0;31m         \u001b[0margs_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m         \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCALL_COMMAND_NAME\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_build_args\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_build_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverters\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1277\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1278\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m             \u001b[0mnew_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_args\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m   1262\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mconverter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcan_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1264\u001b[0;31m                         \u001b[0mtemp_arg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1265\u001b[0m                         \u001b[0mtemp_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_arg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m                         \u001b[0mnew_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_arg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/py4j/java_collections.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, object, gateway_client)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0mjava_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArrayList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m             \u001b[0mjava_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjava_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1313\u001b[0;31m         \u001b[0margs_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m         \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCALL_COMMAND_NAME\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_build_args\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_build_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverters\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1277\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1278\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m             \u001b[0mnew_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_args\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m   1262\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mconverter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcan_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1264\u001b[0;31m                         \u001b[0mtemp_arg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1265\u001b[0m                         \u001b[0mtemp_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_arg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m                         \u001b[0mnew_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_arg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/py4j/java_collections.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, object, gateway_client)\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0mArrayList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJavaClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"java.util.ArrayList\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0mjava_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArrayList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m             \u001b[0mjava_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjava_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pyspark/sql/column.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Column is not iterable\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;31m# string methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Column is not iterable"
     ]
    }
   ],
   "source": [
    "users_df.selectExpr(col(\"id\"),\"first_name\").show()\n",
    "# it will not work as selectExpr accepts only the typical SQL Style syntaxs only\n",
    "# col is pyspark.sql.function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f6ba1cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------------+--------------------+\n",
      "| id|first_name|   last_name|           Full_Name|\n",
      "+---+----------+------------+--------------------+\n",
      "|  1|    Corrie|Van den Oord|Corrie, Van den Oord|\n",
      "|  2|  Nikolaus|     Brewitt|   Nikolaus, Brewitt|\n",
      "|  3|    Orelie|      Penney|      Orelie, Penney|\n",
      "|  4|     Ashby|    Maddocks|     Ashby, Maddocks|\n",
      "|  5|      Kurt|        Rome|          Kurt, Rome|\n",
      "+---+----------+------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_df.select(\n",
    "    \"id\",\n",
    "    \"first_name\",\n",
    "    \"last_name\",\n",
    "    concat(users_df[\"first_name\"],lit(\", \"),col(\"last_name\")).alias(\"Full_Name\")\n",
    ").show()\n",
    "\n",
    "# u can use indexing method to use a particular column eg: users_df[\"first_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "95eee3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------------+\n",
      "| id|first_name|           full_name|\n",
      "+---+----------+--------------------+\n",
      "| id|first_name|Corrie, Van den Oord|\n",
      "| id|first_name|   Nikolaus, Brewitt|\n",
      "| id|first_name|      Orelie, Penney|\n",
      "| id|first_name|     Ashby, Maddocks|\n",
      "| id|first_name|          Kurt, Rome|\n",
      "+---+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_df.createOrReplaceTempView(\"users\")\n",
    "\n",
    "# u can not use indexing method to use a particular column eg: users_df[\"first_name\"]\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "    \"id\",\n",
    "    \"first_name\",\n",
    "    concat(users.first_name,\", \",users.last_name) as full_name\n",
    "    from users\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c951bd49",
   "metadata": {},
   "source": [
    "## Understanding col type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d8ccc05c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'id'>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8b4042ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'id'>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col(\"id\")\n",
    "\n",
    "# passing any string to col - creates a column type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e8a47c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------------+\n",
      "| id|first_name|   last_name|\n",
      "+---+----------+------------+\n",
      "|  1|    Corrie|Van den Oord|\n",
      "|  2|  Nikolaus|     Brewitt|\n",
      "|  3|    Orelie|      Penney|\n",
      "|  4|     Ashby|    Maddocks|\n",
      "|  5|      Kurt|        Rome|\n",
      "+---+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols = [\"id\",\"first_name\",\"last_name\"]\n",
    "users_df.select(*cols).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083ecab6",
   "metadata": {},
   "source": [
    "* There are quite a few functions available on top of column type\n",
    "\n",
    "    * cast (can be used on all important data frame functions such as select, filter, groupBy, orderBy, etc)\n",
    "    * asc, desc (typically used as part of sort or orderBy)\n",
    "    * contains (typically used as part of filter or where)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "67f36805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+\n",
      "| id|  customer|\n",
      "+---+----------+\n",
      "|  1|2021-01-15|\n",
      "|  2|2021-02-14|\n",
      "|  3|2021-01-21|\n",
      "|  4|      null|\n",
      "|  5|      null|\n",
      "+---+----------+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- customer: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import date_format\n",
    "\n",
    "# the date_format - returns a col type only\n",
    "\n",
    "# alias,cast work on col types\n",
    "\n",
    "users_df.select(\n",
    "    col(\"id\"),\n",
    "    date_format(\"customer_from\",\"yyyy-MM-dd\").alias(\"customer\")\n",
    "\n",
    ").show()\n",
    "\n",
    "users_df.select(\n",
    "    col(\"id\"),\n",
    "    date_format(\"customer_from\",\"yyyy-MM-dd\").alias(\"customer\")\n",
    "\n",
    ").printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8a2f5310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+\n",
      "| id|customer_from|\n",
      "+---+-------------+\n",
      "|  1|     20210115|\n",
      "|  2|     20210214|\n",
      "|  3|     20210121|\n",
      "|  4|         null|\n",
      "|  5|         null|\n",
      "+---+-------------+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- customer_from: integer (nullable = true)\n",
      "\n",
      "+---+-------------+\n",
      "| id|customer_from|\n",
      "+---+-------------+\n",
      "|  1|     20210115|\n",
      "|  2|     20210214|\n",
      "|  3|     20210121|\n",
      "|  4|         null|\n",
      "|  5|         null|\n",
      "+---+-------------+\n",
      "\n",
      "+---+-------------+\n",
      "| id|customer_from|\n",
      "+---+-------------+\n",
      "|  1|     20210115|\n",
      "|  2|     20210214|\n",
      "|  3|     20210121|\n",
      "|  4|         null|\n",
      "|  5|         null|\n",
      "+---+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Casting to int\n",
    "\n",
    "users_df.select(\n",
    "    col(\"id\"),\n",
    "    date_format(\"customer_from\",\"yyyyMMdd\").cast(\"int\").alias(\"customer_from\")\n",
    "\n",
    ").show()\n",
    "\n",
    "users_df.select(\n",
    "    col(\"id\"),\n",
    "    date_format(\"customer_from\",\"yyyyMMdd\").cast(\"int\").alias(\"customer_from\")\n",
    "\n",
    ").printSchema()\n",
    "\n",
    "\n",
    "\n",
    "cols = [ col(\"id\"),\n",
    "    date_format(\"customer_from\",\"yyyyMMdd\").cast(\"int\").alias(\"customer_from\")\n",
    "]\n",
    "\n",
    "# the select work for both list of col/strings or strings\n",
    "users_df.select(cols).show() # ------ Takes a list of column or strings  \n",
    "users_df.select(*cols).show() # ----- Takes strings \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cb5148",
   "metadata": {},
   "source": [
    "## Invoking functions using Spark Column Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4365f045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate first name and last name to generate full_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5707fa51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.column.Column'>\n",
      "+---+--------------------+\n",
      "| id|           full_name|\n",
      "+---+--------------------+\n",
      "|  1|Corrie, Van den Oord|\n",
      "|  2|   Nikolaus, Brewitt|\n",
      "|  3|      Orelie, Penney|\n",
      "|  4|     Ashby, Maddocks|\n",
      "|  5|          Kurt, Rome|\n",
      "+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "full_name = concat(col(\"first_name\"),lit(\", \"),col(\"last_name\")).alias(\"full_name\")\n",
    "\n",
    "print(type(full_name))\n",
    "\n",
    "users_df.select(\"id\",full_name).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b1a17dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|  date|\n",
      "+------+\n",
      "|210015|\n",
      "|210014|\n",
      "|210021|\n",
      "|  null|\n",
      "|  null|\n",
      "+------+\n",
      "\n",
      "root\n",
      " |-- date: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "formats = date_format(\"customer_from\",\"yymmdd\").cast(\"int\").alias(\"date\")\n",
    "\n",
    "users_df.select(formats).show()\n",
    "\n",
    "users_df.select(formats).printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a89cd1",
   "metadata": {},
   "source": [
    "## Understanding lit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f1a67618",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  users_df.select(\"id\",\"amount_paid\"+lit(25)).show()   # returns Null\n",
    "# operation of string with col type - doesnt work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fc603bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,concat,lit\n",
    "\n",
    "# lit ( literal )- add the new content \n",
    "# lit Reference - https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.lit.html?highlight=lit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d2181c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.column.Column"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(col(\"amount_paid\")+\"25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d90e3035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+\n",
      "| id|(amount_paid + 25)|\n",
      "+---+------------------+\n",
      "|  1|           1025.55|\n",
      "|  2|             925.0|\n",
      "|  3|            875.55|\n",
      "|  4|               NaN|\n",
      "|  5|               NaN|\n",
      "+---+------------------+\n",
      "\n",
      "+---+-----------+\n",
      "| id|amount_paid|\n",
      "+---+-----------+\n",
      "|  1|    1025.55|\n",
      "|  2|      925.0|\n",
      "|  3|     875.55|\n",
      "|  4|        NaN|\n",
      "|  5|        NaN|\n",
      "+---+-----------+\n",
      "\n",
      "+---+------------------+\n",
      "| id|(amount_paid + 25)|\n",
      "+---+------------------+\n",
      "|  1|           1025.55|\n",
      "|  2|             925.0|\n",
      "|  3|            875.55|\n",
      "|  4|               NaN|\n",
      "|  5|               NaN|\n",
      "+---+------------------+\n",
      "\n",
      "+---+------------------+\n",
      "| id|(amount_paid + 25)|\n",
      "+---+------------------+\n",
      "|  1|           1025.55|\n",
      "|  2|             925.0|\n",
      "|  3|            875.55|\n",
      "|  4|               NaN|\n",
      "|  5|               NaN|\n",
      "+---+------------------+\n",
      "\n",
      "<class 'pyspark.sql.column.Column'>\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "cannot resolve 'amount_paid25' given input columns: [amount_paid, courses, customer_from, email, first_name, id, is_customer, last_name, last_updated_ts, phone_numbers];\n'Project [id#0L, 'amount_paid25]\n+- LogicalRDD [id#0L, first_name#1, last_name#2, email#3, phone_numbers#4, courses#5, is_customer#6, amount_paid#7, customer_from#8, last_updated_ts#9], false\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7z/zf4v6y0d1q5bnv1v6p7tmvq80000gn/T/ipykernel_59948/565393260.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0musers_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"amount_paid\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"25\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# the above one fails as there is no column named amount_paid25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   1683\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Alice'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Bob'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m         \"\"\"\n\u001b[0;32m-> 1685\u001b[0;31m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: cannot resolve 'amount_paid25' given input columns: [amount_paid, courses, customer_from, email, first_name, id, is_customer, last_name, last_updated_ts, phone_numbers];\n'Project [id#0L, 'amount_paid25]\n+- LogicalRDD [id#0L, first_name#1, last_name#2, email#3, phone_numbers#4, courses#5, is_customer#6, amount_paid#7, customer_from#8, last_updated_ts#9], false\n"
     ]
    }
   ],
   "source": [
    "# using Spark SQL\n",
    "\n",
    "users_df.createOrReplaceTempView(\"users\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    select id,amount_paid +25\n",
    "    from users\n",
    "\n",
    "\"\"\").show()\n",
    "\n",
    "users_df.selectExpr(\"id\",'amount_paid+25 AS amount_paid').show()\n",
    "\n",
    "users_df.select(\"id\",users_df.amount_paid+lit(25)).show()\n",
    "                \n",
    "#  users_df.select(\"id\",\"amount_paid\"+lit(25)).show()   # returns Null\n",
    "\n",
    "# lit - converts a literal to column type\n",
    "\n",
    "\n",
    "\n",
    "users_df.select(\"id\",col(\"amount_paid\")+\"25\").show() ##- it works \n",
    "# the above works as col(\"amount_paid\")+\"25\" is also a Col\n",
    "print(type(col(\"amount_paid\")+\"25\"))\n",
    "\n",
    "\n",
    "users_df.select(\"id\",\"amount_paid\"+\"25\").show()\n",
    "\n",
    "# the above one fails as there is no column named amount_paid25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ba42d1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| id|(25.0 + amount_paid)|\n",
      "+---+--------------------+\n",
      "|  1|                null|\n",
      "|  2|                null|\n",
      "|  3|                null|\n",
      "|  4|                null|\n",
      "|  5|                null|\n",
      "+---+--------------------+\n",
      "\n",
      "+---+--------------------------+\n",
      "| id|concat(amount_paid,  25.0)|\n",
      "+---+--------------------------+\n",
      "|  1|              1000.55 25.0|\n",
      "|  2|                900.0 25.0|\n",
      "|  3|               850.55 25.0|\n",
      "|  4|                  NaN 25.0|\n",
      "|  5|                  NaN 25.0|\n",
      "+---+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_df.select(\"id\",\"amount_paid\"+lit(\"25.0\")).show()\n",
    "\n",
    "users_df.select(\"id\",concat(\"amount_paid\",lit(\" 25.0\"))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbe1d08",
   "metadata": {},
   "source": [
    "## Renaming the Spark DataFrame Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052e8627",
   "metadata": {},
   "source": [
    "* There are multiple ways to rename Spark Data Frame Columns or Expressions.\n",
    "\n",
    "    * We can rename column or expression using alias as part of select\n",
    "    * We can add or rename column or expression using withColumn on top of Data Frame.\n",
    "    * We can rename one column at a time using withColumnRenamed on top of Data Frame.\n",
    "    * We typically use withColumn to perform row level transformations and then to provide a name to the result. If we provide the same name as existing column, then the column will be replaced with new one.\n",
    "    * If we want to just rename the column then it is better to use withColumnRenamed.\n",
    "    * If we want to apply any transformation, we need to either use select or withColumn\n",
    "    * We can rename bunch of columns using toDF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f0adca",
   "metadata": {},
   "source": [
    "## Naming Derived Columns using withColumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a356399",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
