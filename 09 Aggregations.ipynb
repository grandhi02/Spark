{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "189f8558",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 167:>                                                        (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "     \n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
    "\n",
    "order_items = spark.read.json(\"order_items.csv\")\n",
    "\n",
    "orders = spark.read.json(\"orders.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "21b12dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+---------------------+------------------------+-------------------+-------------------+\n",
      "|order_item_id|order_item_order_id|order_item_product_id|order_item_product_price|order_item_quantity|order_item_subtotal|\n",
      "+-------------+-------------------+---------------------+------------------------+-------------------+-------------------+\n",
      "|            1|                  1|                  957|                  299.98|                  1|             299.98|\n",
      "|            2|                  2|                 1073|                  199.99|                  1|             199.99|\n",
      "|            3|                  2|                  502|                    50.0|                  5|              250.0|\n",
      "|            4|                  2|                  403|                  129.99|                  1|             129.99|\n",
      "|            5|                  4|                  897|                   24.99|                  2|              49.98|\n",
      "+-------------+-------------------+---------------------+------------------------+-------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_items.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19e7b2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_item_id: long (nullable = true)\n",
      " |-- order_item_order_id: long (nullable = true)\n",
      " |-- order_item_product_id: long (nullable = true)\n",
      " |-- order_item_product_price: double (nullable = true)\n",
      " |-- order_item_quantity: long (nullable = true)\n",
      " |-- order_item_subtotal: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a315d6d",
   "metadata": {},
   "source": [
    "## Aggregate functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87a8697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The common aggregate functions that are available as part of pyspark.sql.functions\n",
    "\n",
    "# count\n",
    "# sum\n",
    "# min\n",
    "# max\n",
    "# avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eee2bbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba012663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function count in module pyspark.sql.functions:\n",
      "\n",
      "count(col)\n",
      "    Aggregate function: returns the number of items in a group.\n",
      "    \n",
      "    .. versionadded:: 1.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "176453e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  172198|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.select(count(\"*\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "17780747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+\n",
      "|order_item_id|count(1)|\n",
      "+-------------+--------+\n",
      "|           26|       1|\n",
      "|           29|       1|\n",
      "|          474|       1|\n",
      "|          964|       1|\n",
      "|         1677|       1|\n",
      "+-------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_items.groupBy(\"order_item_id\").agg(count(\"*\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5955482",
   "metadata": {},
   "source": [
    "# Get number of records in order_items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7cfe369c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  172198|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function count on data frame is action. It will trigger execution.\n",
    "\n",
    "order_items.count() # it is called action as it immediately triggers execution\n",
    "     \n",
    "\n",
    "order_items.count()\n",
    "\n",
    "print(type(order_items.count()))\n",
    "\n",
    "\n",
    "# or by sql type syntax\n",
    "\n",
    "order_items.select(count(\"*\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b22992e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  172198|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## or\n",
    "\n",
    "\n",
    "# count is transformation (wide).\n",
    "# Execution will be triggered when we perform actions such as show\n",
    "\n",
    "order_items.select(count(\"*\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef9ea0d",
   "metadata": {},
   "source": [
    "## tOTAL Aggregations on Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd9e52b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('order_item_id', 'bigint'),\n",
       " ('order_item_order_id', 'bigint'),\n",
       " ('order_item_product_id', 'bigint'),\n",
       " ('order_item_product_price', 'double'),\n",
       " ('order_item_quantity', 'bigint'),\n",
       " ('order_item_subtotal', 'double')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_items.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "077e6ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get revence using order_item_subtotal for a given order_item_order_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fcb8223f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "704b4497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+\n",
      "|order_item_order_id|               sum|\n",
      "+-------------------+------------------+\n",
      "|                  1|            299.98|\n",
      "|                  2|            579.98|\n",
      "|                  4|            699.85|\n",
      "|                  5|1129.8600000000001|\n",
      "|                  7| 579.9200000000001|\n",
      "+-------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_items.groupBy(\"order_item_order_id\").\\\n",
    "        agg(sum(\"order_item_subtotal\").alias(\"sum\")).\\\n",
    "        sort(\"order_item_order_id\",ascending =1).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6eb2cebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_item_id: long (nullable = true)\n",
      " |-- order_item_order_id: long (nullable = true)\n",
      " |-- order_item_product_id: long (nullable = true)\n",
      " |-- order_item_product_price: double (nullable = true)\n",
      " |-- order_item_quantity: long (nullable = true)\n",
      " |-- order_item_subtotal: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_items.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b1d9454a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## for a order_id =2, Get number of item, total quantity as well as revenue for given order item , order id \n",
    "\n",
    "\n",
    "    # Number of items can be computed using count on order_item_quantity\n",
    "    # Total quantity can be computed using sum on order_item_quantity\n",
    "    # Total Revenue can be computed using sum on order_item_subtotal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ee7d93f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+------------------------+\n",
      "|count(1)|sum|sum(order_item_subtotal)|\n",
      "+--------+---+------------------------+\n",
      "|       3|  7|                  579.98|\n",
      "+--------+---+------------------------+\n",
      "\n",
      "+--------+---+------------------------+\n",
      "|count(1)|sum|sum(order_item_subtotal)|\n",
      "+--------+---+------------------------+\n",
      "|       3|  7|                  579.98|\n",
      "+--------+---+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# a\n",
    "\n",
    "# count(*) is same as count(col(\"col_name\"))\n",
    "\n",
    "# SQL Type syntax\n",
    "\n",
    "order_items.\\\n",
    "    filter(\"order_item_order_id = 2\").\\\n",
    "    select(count(\"*\"),sum(\"order_item_quantity\").alias(\"sum\"),sum(\"order_item_subtotal\")\n",
    "          \n",
    "          ).show()\n",
    "\n",
    "# or\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "order_items.\\\n",
    "    filter(col(\"order_item_order_id\") == 2).\\\n",
    "    select(count(\"*\"),sum(\"order_item_quantity\").alias(\"sum\"),sum(\"order_item_subtotal\")\n",
    "          \n",
    "          ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a27b92a",
   "metadata": {},
   "source": [
    "## GroupBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e2617a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a36e5811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method groupBy in module pyspark.sql.dataframe:\n",
      "\n",
      "groupBy(*cols) method of pyspark.sql.dataframe.DataFrame instance\n",
      "    Groups the :class:`DataFrame` using the specified columns,\n",
      "    so we can run aggregation on them. See :class:`GroupedData`\n",
      "    for all the available aggregate functions.\n",
      "    \n",
      "    :func:`groupby` is an alias for :func:`groupBy`.\n",
      "    \n",
      "    .. versionadded:: 1.3.0\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    cols : list, str or :class:`Column`\n",
      "        columns to group by.\n",
      "        Each element should be a column name (string) or an expression (:class:`Column`).\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df.groupBy().avg().collect()\n",
      "    [Row(avg(age)=3.5)]\n",
      "    >>> sorted(df.groupBy('name').agg({'age': 'mean'}).collect())\n",
      "    [Row(name='Alice', avg(age)=2.0), Row(name='Bob', avg(age)=5.0)]\n",
      "    >>> sorted(df.groupBy(df.name).avg().collect())\n",
      "    [Row(name='Alice', avg(age)=2.0), Row(name='Bob', avg(age)=5.0)]\n",
      "    >>> sorted(df.groupBy(['name', df.age]).count().collect())\n",
      "    [Row(name='Alice', age=2, count=1), Row(name='Bob', age=5, count=1)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(order_items.groupBy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "266df41c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[min(order_item_id): bigint, min(order_item_order_id): bigint, min(order_item_product_id): bigint, min(order_item_product_price): double, min(order_item_quantity): bigint, min(order_item_subtotal): double]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_items.groupBy().min()\n",
    "\n",
    "# it calculates min of all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a19017f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------------+--------------------------+-----------------------------+------------------------+------------------------+\n",
      "|min(order_item_id)|min(order_item_order_id)|min(order_item_product_id)|min(order_item_product_price)|min(order_item_quantity)|min(order_item_subtotal)|\n",
      "+------------------+------------------------+--------------------------+-----------------------------+------------------------+------------------------+\n",
      "|                 1|                       1|                        19|                         9.99|                       1|                    9.99|\n",
      "+------------------+------------------------+--------------------------+-----------------------------+------------------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_items.groupBy().min().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "801f7442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.group.GroupedData'>\n",
      "+-------------+-----+\n",
      "|order_item_id|count|\n",
      "+-------------+-----+\n",
      "|           26|    1|\n",
      "|           29|    1|\n",
      "|          474|    1|\n",
      "|          964|    1|\n",
      "|         1677|    1|\n",
      "+-------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_items_grouped = order_items.groupBy(\"order_item_id\")\n",
    "\n",
    "# it creates a dataframe type groupedData\n",
    "\n",
    "print(type(order_items_grouped))\n",
    "\n",
    "order_items_grouped.count().show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c8699fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method count in module pyspark.sql.group:\n",
      "\n",
      "count() method of pyspark.sql.group.GroupedData instance\n",
      "    Counts the number of records for each group.\n",
      "    \n",
      "    .. versionadded:: 1.3.0\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> sorted(df.groupBy(df.age).count().collect())\n",
      "    [Row(age=2, count=1), Row(age=5, count=1)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(order_items_grouped.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ef20dba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 169:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "||\n",
      "++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "## for non-numeric columns - min ,max will not be used on those columns\n",
    "\n",
    "order.groupBy().min().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6134e20e",
   "metadata": {},
   "source": [
    "## Perform Grouped Aggregations using direct functions on Spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9092884f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.group.GroupedData"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_items_grouped = order_items.groupBy(\"order_item_order_id\")\n",
    "\n",
    "# it creates a dataframe type groupedData\n",
    "\n",
    "type(order_items_grouped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3cdee0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|order_item_order_id|count|\n",
      "+-------------------+-----+\n",
      "|                 29|    5|\n",
      "|                474|    5|\n",
      "|                964|    4|\n",
      "|               1677|    5|\n",
      "|               1806|    3|\n",
      "+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------------------+-----------+\n",
      "|order_item_order_id|order_count|\n",
      "+-------------------+-----------+\n",
      "|                 29|          5|\n",
      "|                474|          5|\n",
      "|                964|          4|\n",
      "|               1677|          5|\n",
      "|               1806|          3|\n",
      "+-------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# The aggregate functions will be worked on the groups of that specific column\n",
    "\n",
    "# count on one column or more columns, the value will be sane\n",
    "\n",
    "order_items_grouped.count().show(5)\n",
    "\n",
    "\n",
    "# or\n",
    "\n",
    "order_items_grouped.\\\n",
    "        count().\\\n",
    "        withColumnRenamed(\"count\",\"order_count\").\\\n",
    "        show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "382df5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+------------------------+--------------------------+-----------------------------+------------------------+------------------------+\n",
      "|order_item_order_id|sum(order_item_id)|sum(order_item_order_id)|sum(order_item_product_id)|sum(order_item_product_price)|sum(order_item_quantity)|sum(order_item_subtotal)|\n",
      "+-------------------+------------------+------------------------+--------------------------+-----------------------------+------------------------+------------------------+\n",
      "|                 29|               425|                     145|                      3897|            909.9300000000001|                       9|                 1109.85|\n",
      "|                474|              5815|                    2370|                      4508|           374.94000000000005|                      13|       774.8199999999999|\n",
      "|                964|              9586|                    3856|                      2964|           499.95000000000005|                      11|       739.8800000000001|\n",
      "|               1677|             20860|                    8385|                      2357|                       277.97|                      14|       649.9200000000001|\n",
      "|               1806|             13545|                    5418|                      1871|                       509.97|                       8|                  789.94|\n",
      "+-------------------+------------------+------------------------+--------------------------+-----------------------------+------------------------+------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_items_grouped.\\\n",
    "        sum().\\\n",
    "        show(5)\n",
    "\n",
    "# we get sum of all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9f7e28b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------------+------------------------+\n",
      "|order_item_order_id|sum(order_item_quantity)|sum(order_item_subtotal)|\n",
      "+-------------------+------------------------+------------------------+\n",
      "|                 29|                       9|                 1109.85|\n",
      "|                474|                      13|       774.8199999999999|\n",
      "|                964|                      11|       739.8800000000001|\n",
      "|               1677|                      14|       649.9200000000001|\n",
      "|               1806|                       8|                  789.94|\n",
      "+-------------------+------------------------+------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# to get sum of specific columns\n",
    "\n",
    "order_items_grouped.\\\n",
    "        sum(\"order_item_quantity\",\"order_item_subtotal\").\\\n",
    "        show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3bf848c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-------------------+\n",
      "|order_item_order_id|order_item_quantity|order_item_subtotal|\n",
      "+-------------------+-------------------+-------------------+\n",
      "|                 29|                  9|            1109.85|\n",
      "|                474|                 13|  774.8199999999999|\n",
      "|                964|                 11|  739.8800000000001|\n",
      "|               1677|                 14|  649.9200000000001|\n",
      "|               1806|                  8|             789.94|\n",
      "+-------------------+-------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------------------+--------------+--------------+\n",
      "|order_item_order_id|order_quantity|order_subtotal|\n",
      "+-------------------+--------------+--------------+\n",
      "|                 29|             9|       1109.85|\n",
      "|                474|            13|        774.82|\n",
      "|                964|            11|        739.88|\n",
      "|               1677|            14|        649.92|\n",
      "|               1806|             8|        789.94|\n",
      "+-------------------+--------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# in order to get custom column names, use toDF\n",
    "\n",
    "order_items_grouped.\\\n",
    "        sum(\"order_item_quantity\",\"order_item_subtotal\").\\\n",
    "        toDF(\"order_item_order_id\",\"order_item_quantity\",\"order_item_subtotal\")\\\n",
    "        .show(5)\n",
    "\n",
    "# Use Round to round the order_item_subtotal\n",
    "\n",
    "from pyspark.sql.functions import round\n",
    "\n",
    "order_items_grouped.\\\n",
    "        sum(\"order_item_quantity\",\"order_item_subtotal\").\\\n",
    "        toDF(\"order_item_order_id\",\"order_quantity\",\"order_subtotal\").\\\n",
    "        withColumn(\"order_subtotal\",round(\"order_subtotal\",2))\\\n",
    "        .show(5)\n",
    "\n",
    "# # keep in mind that , we can have only one aggregate function on top of grouped dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a373f21d",
   "metadata": {},
   "source": [
    "## Multiple aggregation methods on single grouped dataframe using agg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9fb501dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------------+\n",
      "|order_item_order_id|sum(order_item_quantity)|\n",
      "+-------------------+------------------------+\n",
      "|                 29|                       9|\n",
      "|                474|                      13|\n",
      "|                964|                      11|\n",
      "|               1677|                      14|\n",
      "|               1806|                       8|\n",
      "|               1950|                      12|\n",
      "|               2214|                       5|\n",
      "|               2250|                      10|\n",
      "|               2453|                       7|\n",
      "|               2509|                       4|\n",
      "|               2529|                       1|\n",
      "|               2927|                       8|\n",
      "|               3091|                       5|\n",
      "|               3764|                       2|\n",
      "|               4590|                      11|\n",
      "|               4894|                       4|\n",
      "|               5385|                      10|\n",
      "|               5409|                       7|\n",
      "|               6721|                       3|\n",
      "|               7225|                      11|\n",
      "+-------------------+------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'min'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7z/zf4v6y0d1q5bnv1v6p7tmvq80000gn/T/ipykernel_7512/2046830026.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# we can not use max,min on top of this sum as it returns a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0morder_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"order_item_quantity\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1657\u001b[0m         \"\"\"\n\u001b[1;32m   1658\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1659\u001b[0;31m             raise AttributeError(\n\u001b[0m\u001b[1;32m   1660\u001b[0m                 \"'%s' object has no attribute '%s'\" % (self.__class__.__name__, name))\n\u001b[1;32m   1661\u001b[0m         \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'min'"
     ]
    }
   ],
   "source": [
    "order_items.grouped = order_items.groupBy(\"order_item_order_id\") \n",
    "\n",
    "# This is of type groupedData, we can use agg func like min,max,sum on top of it directly\n",
    "\n",
    "# or use the agg() method\n",
    "\n",
    "\n",
    "order_items.grouped.sum(\"order_item_quantity\").show()\n",
    "\n",
    "# we can not use max,min on top of this sum as it returns a Dataframe\n",
    "\n",
    "order_items.grouped.sum(\"order_item_quantity\").min().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "80367daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method agg in module pyspark.sql.group:\n",
      "\n",
      "agg(*exprs) method of pyspark.sql.group.GroupedData instance\n",
      "    Compute aggregates and returns the result as a :class:`DataFrame`.\n",
      "    \n",
      "    The available aggregate functions can be:\n",
      "    \n",
      "    1. built-in aggregation functions, such as `avg`, `max`, `min`, `sum`, `count`\n",
      "    \n",
      "    2. group aggregate pandas UDFs, created with :func:`pyspark.sql.functions.pandas_udf`\n",
      "    \n",
      "       .. note:: There is no partial aggregation with group aggregate UDFs, i.e.,\n",
      "           a full shuffle is required. Also, all the data of a group will be loaded into\n",
      "           memory, so the user should be aware of the potential OOM risk if data is skewed\n",
      "           and certain groups are too large to fit in memory.\n",
      "    \n",
      "       .. seealso:: :func:`pyspark.sql.functions.pandas_udf`\n",
      "    \n",
      "    If ``exprs`` is a single :class:`dict` mapping from string to string, then the key\n",
      "    is the column to perform aggregation on, and the value is the aggregate function.\n",
      "    \n",
      "    Alternatively, ``exprs`` can also be a list of aggregate :class:`Column` expressions.\n",
      "    \n",
      "    .. versionadded:: 1.3.0\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    exprs : dict\n",
      "        a dict mapping from column name (string) to aggregate functions (string),\n",
      "        or a list of :class:`Column`.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Built-in aggregation functions and group aggregate pandas UDFs cannot be mixed\n",
      "    in a single call to this function.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> gdf = df.groupBy(df.name)\n",
      "    >>> sorted(gdf.agg({\"*\": \"count\"}).collect())\n",
      "    [Row(name='Alice', count(1)=1), Row(name='Bob', count(1)=1)]\n",
      "    \n",
      "    >>> from pyspark.sql import functions as F\n",
      "    >>> sorted(gdf.agg(F.min(df.age)).collect())\n",
      "    [Row(name='Alice', min(age)=2), Row(name='Bob', min(age)=5)]\n",
      "    \n",
      "    >>> from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
      "    >>> @pandas_udf('int', PandasUDFType.GROUPED_AGG)  # doctest: +SKIP\n",
      "    ... def min_udf(v):\n",
      "    ...     return v.min()\n",
      "    >>> sorted(gdf.agg(min_udf(df.age)).collect())  # doctest: +SKIP\n",
      "    [Row(name='Alice', min_udf(age)=2), Row(name='Bob', min_udf(age)=5)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(order_items_grouped.agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "83597ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_item_order_id: long (nullable = true)\n",
      " |-- sum(order_item_quantity): long (nullable = true)\n",
      " |-- sum(order_item_subtotal): double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_items.grouped.\\\n",
    "            agg(sum(\"order_item_quantity\"),sum(\"order_item_subtotal\")).printSchema()\n",
    "\n",
    "# sum(\"col_name\") - it returns a column object only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3ac0f458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------------+----------------------------------+\n",
      "|order_item_order_id|sum(order_item_quantity)|round(sum(order_item_subtotal), 2)|\n",
      "+-------------------+------------------------+----------------------------------+\n",
      "|                 29|                       9|                           1109.85|\n",
      "|                474|                      13|                            774.82|\n",
      "|                964|                      11|                            739.88|\n",
      "|               1677|                      14|                            649.92|\n",
      "|               1806|                       8|                            789.94|\n",
      "|               1950|                      12|                           1015.87|\n",
      "|               2214|                       5|                            449.96|\n",
      "|               2250|                      10|                            889.94|\n",
      "|               2453|                       7|                            999.93|\n",
      "|               2509|                       4|                            889.94|\n",
      "|               2529|                       1|                             59.99|\n",
      "|               2927|                       8|                            999.91|\n",
      "|               3091|                       5|                            469.93|\n",
      "|               3764|                       2|                             95.98|\n",
      "|               4590|                      11|                            949.83|\n",
      "|               4894|                       4|                            899.94|\n",
      "|               5385|                      10|                            629.86|\n",
      "|               5409|                       7|                            699.92|\n",
      "|               6721|                       3|                            139.99|\n",
      "|               7225|                      11|                            774.86|\n",
      "+-------------------+------------------------+----------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_items.grouped.\\\n",
    "            agg(sum(\"order_item_quantity\"),round(sum(\"order_item_subtotal\"),2)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2541197",
   "metadata": {},
   "source": [
    "\n",
    "# we can also pass the dict to agg()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8026e9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_item_order_id: long (nullable = true)\n",
      " |-- sum(order_item_subtotal): double (nullable = true)\n",
      " |-- sum(order_item_quantity): long (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/07/05 21:13:04 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 1018111 ms exceeds timeout 120000 ms\n",
      "23/07/05 21:13:04 WARN SparkContext: Killing executors is not supported by current scheduler.\n"
     ]
    }
   ],
   "source": [
    "order_items.grouped.\\\n",
    "            agg( {\"order_item_quantity\":\"sum\",\"order_item_subtotal\":\"sum\"} ).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ccb4a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
